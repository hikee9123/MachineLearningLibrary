<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.13">
  <compounddef id="classmlpack_1_1rl_1_1DoublePoleCart" kind="class" language="C++" prot="public">
    <compoundname>mlpack::rl::DoublePoleCart</compoundname>
    <includes refid="double__pole__cart_8hpp" local="no">double_pole_cart.hpp</includes>
    <innerclass refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action" prot="public">mlpack::rl::DoublePoleCart::Action</innerclass>
    <innerclass refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" prot="public">mlpack::rl::DoublePoleCart::State</innerclass>
      <sectiondef kind="private-attrib">
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a0c790792348e951b9e3606edc7bb532b" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double doneReward</definition>
        <argsstring></argsstring>
        <name>doneReward</name>
        <briefdescription>
<para>Locally-stored done reward. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="366" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="366" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1af84c19eb99402801ccb9228ed11c624b" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double forceMag</definition>
        <argsstring></argsstring>
        <name>forceMag</name>
        <briefdescription>
<para>Locally-stored magnitude of the applied force. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="354" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="354" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a922f2c43a75edbe2ee21ea7ba7b5cb2c" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double gravity</definition>
        <argsstring></argsstring>
        <name>gravity</name>
        <briefdescription>
<para>Locally-stored gravity. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="348" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="348" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1ad7a541093aca44890413459c6248db6c" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double l1</definition>
        <argsstring></argsstring>
        <name>l1</name>
        <briefdescription>
<para>Locally-stored length of the first pole. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="342" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="342" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1afc8165026561b3471131feeb5a613d1f" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double l2</definition>
        <argsstring></argsstring>
        <name>l2</name>
        <briefdescription>
<para>Locally-stored length of. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="345" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="345" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a3aa17605b09d35b6df9edb2102876fc5" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double m1</definition>
        <argsstring></argsstring>
        <name>m1</name>
        <briefdescription>
<para>Locally-stored mass of the first pole. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="336" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="336" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a59022b29ceaad8397fe7ab1c6041e54e" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double m2</definition>
        <argsstring></argsstring>
        <name>m2</name>
        <briefdescription>
<para>Locally-stored mass of the second pole. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="339" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="339" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1ad73a528bed94e8954100366adc2134f7" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double massCart</definition>
        <argsstring></argsstring>
        <name>massCart</name>
        <briefdescription>
<para>Locally-stored mass of the cart. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="351" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="351" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1ac29b91fba0f71e460dee7cf4c503e01a" prot="private" static="no" mutable="no">
        <type>size_t</type>
        <definition>size_t maxSteps</definition>
        <argsstring></argsstring>
        <name>maxSteps</name>
        <briefdescription>
<para>Locally-stored maximum number of steps. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="333" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="333" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1ae754109e026bb4da3884361bd386d333" prot="private" static="no" mutable="no">
        <type>size_t</type>
        <definition>size_t stepsPerformed</definition>
        <argsstring></argsstring>
        <name>stepsPerformed</name>
        <briefdescription>
<para>Locally-stored number of steps performed. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="369" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="369" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1ae5f7c26321910a384f6f0d37910858a2" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double tau</definition>
        <argsstring></argsstring>
        <name>tau</name>
        <briefdescription>
<para>Locally-stored time interval. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="357" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="357" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a0b053ab37ab8ea4317f303387605fbf1" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double thetaThresholdRadians</definition>
        <argsstring></argsstring>
        <name>thetaThresholdRadians</name>
        <briefdescription>
<para>Locally-stored maximum angle. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="360" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="360" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="classmlpack_1_1rl_1_1DoublePoleCart_1a675084def3543d22976ea065dad26f51" prot="private" static="no" mutable="no">
        <type>double</type>
        <definition>double xThreshold</definition>
        <argsstring></argsstring>
        <name>xThreshold</name>
        <briefdescription>
<para>Locally-stored maximum position. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="363" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="363" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="public-func">
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1a06e56cc33403fd32ffa82a1b7065bd71" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type></type>
        <definition>DoublePoleCart</definition>
        <argsstring>(const size_t maxSteps=0, const double m1=0.1, const double m2=0.01, const double l1=0.5, const double l2=0.05, const double gravity=9.8, const double massCart=1.0, const double forceMag=10.0, const double tau=0.02, const double thetaThresholdRadians=36 *2 *3.1416/360, const double xThreshold=2.4, const double doneReward=0.0)</argsstring>
        <name>DoublePoleCart</name>
        <param>
          <type>const size_t</type>
          <declname>maxSteps</declname>
          <defval>0</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>m1</declname>
          <defval>0.1</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>m2</declname>
          <defval>0.01</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>l1</declname>
          <defval>0.5</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>l2</declname>
          <defval>0.05</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>gravity</declname>
          <defval>9.8</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>massCart</declname>
          <defval>1.0</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>forceMag</declname>
          <defval>10.0</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>tau</declname>
          <defval>0.02</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>thetaThresholdRadians</declname>
          <defval>36 *2 *3.1416/360</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>xThreshold</declname>
          <defval>2.4</defval>
        </param>
        <param>
          <type>const double</type>
          <declname>doneReward</declname>
          <defval>0.0</defval>
        </param>
        <briefdescription>
<para>Construct a Double Pole Cart instance using the given constants. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>maxSteps</parametername>
</parameternamelist>
<parameterdescription>
<para>The number of steps after which the episode terminates. If the value is 0, there is no limit. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>m1</parametername>
</parameternamelist>
<parameterdescription>
<para>The mass of the first pole. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>m2</parametername>
</parameternamelist>
<parameterdescription>
<para>The mass of the second pole. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>l1</parametername>
</parameternamelist>
<parameterdescription>
<para>The length of the first pole. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>l2</parametername>
</parameternamelist>
<parameterdescription>
<para>The length of the second pole. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>gravity</parametername>
</parameternamelist>
<parameterdescription>
<para>The gravity constant. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>massCart</parametername>
</parameternamelist>
<parameterdescription>
<para>The mass of the cart. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>forceMag</parametername>
</parameternamelist>
<parameterdescription>
<para>The magnitude of the applied force. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>tau</parametername>
</parameternamelist>
<parameterdescription>
<para>The time interval. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>thetaThresholdRadians</parametername>
</parameternamelist>
<parameterdescription>
<para>The maximum angle. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>xThreshold</parametername>
</parameternamelist>
<parameterdescription>
<para>The maximum position. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>doneReward</parametername>
</parameternamelist>
<parameterdescription>
<para>Reward recieved by agent on success. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="123" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="123" bodyend="148"/>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1aec6c83f7450927b7520a0c057babc128" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>void Dsdt</definition>
        <argsstring>(const State &amp;state, const Action &amp;action, arma::vec &amp;dydx)</argsstring>
        <name>Dsdt</name>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>state</declname>
        </param>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action" kindref="compound">Action</ref> &amp;</type>
          <declname>action</declname>
        </param>
        <param>
          <type>arma::vec &amp;</type>
          <declname>dydx</declname>
        </param>
        <briefdescription>
<para>This is the ordinary differential equations required for estimation of next state through RK4 method. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>state</parametername>
</parameternamelist>
<parameterdescription>
<para>The current state. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>action</parametername>
</parameternamelist>
<parameterdescription>
<para>The action taken. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>dydx</parametername>
</parameternamelist>
<parameterdescription>
<para>The differential. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="197" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="197" bodyend="227"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action_1aae7cee579dae25461f6f47c95c41bd9a" compoundref="double__pole__cart_8hpp" startline="100">DoublePoleCart::Action::action</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a6faedb6fad4a1761e5bc5f2c9f061131" compoundref="double__pole__cart_8hpp" startline="68" endline="68">DoublePoleCart::State::Angle</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1adee020824f1381e77738134cb3e74c70" compoundref="double__pole__cart_8hpp" startline="73" endline="73">DoublePoleCart::State::AngularVelocity</references>
        <referencedby refid="classmlpack_1_1rl_1_1DoublePoleCart_1afb8fc975886aa60312d63dff046af34a" compoundref="double__pole__cart_8hpp" startline="238" endline="268">DoublePoleCart::RK4</referencedby>
        <referencedby refid="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" compoundref="double__pole__cart_8hpp" startline="159" endline="187">DoublePoleCart::Sample</referencedby>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1aa9f537249fa0c1e62b38197996ab4c6a" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type><ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref></type>
        <definition>State InitialSample</definition>
        <argsstring>()</argsstring>
        <name>InitialSample</name>
        <briefdescription>
<para>Initial state representation is randomly generated within [-0.05, 0.05]. </para>        </briefdescription>
        <detaileddescription>
<para><simplesect kind="return"><para>Initial state for each episode. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="289" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="289" bodyend="293"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a790355057d12e9c1ce7643551c16fecd" compoundref="double__pole__cart_8hpp" startline="41" endline="42">DoublePoleCart::State::State</references>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1a7fd056133dfd315e4bf45c408f99326f" prot="public" static="no" const="yes" explicit="no" inline="yes" virt="non-virtual">
        <type>bool</type>
        <definition>bool IsTerminal</definition>
        <argsstring>(const State &amp;state) const</argsstring>
        <name>IsTerminal</name>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>state</declname>
        </param>
        <briefdescription>
<para>This function checks if the car has reached the terminal state. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>state</parametername>
</parameternamelist>
<parameterdescription>
<para>The desired state. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>true if state is a terminal state, otherwise false. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="301" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="301" bodyend="321"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a6faedb6fad4a1761e5bc5f2c9f061131" compoundref="double__pole__cart_8hpp" startline="68" endline="68">DoublePoleCart::State::Angle</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1adc41cb3d3f5bdd1bd67dc963ce78c20c" compoundref="double__pole__cart_8hpp" startline="58" endline="58">DoublePoleCart::State::Position</references>
        <referencedby refid="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" compoundref="double__pole__cart_8hpp" startline="159" endline="187">DoublePoleCart::Sample</referencedby>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1ad8fd6d8f7581c82e73556491b79a8907" prot="public" static="no" const="yes" explicit="no" inline="yes" virt="non-virtual">
        <type>size_t</type>
        <definition>size_t MaxSteps</definition>
        <argsstring>() const</argsstring>
        <name>MaxSteps</name>
        <briefdescription>
<para>Get the maximum number of steps allowed. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="327" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="327" bodyend="327"/>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1a64c84cebc489c6fdfd7f057e127b0aef" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>size_t &amp;</type>
        <definition>size_t&amp; MaxSteps</definition>
        <argsstring>()</argsstring>
        <name>MaxSteps</name>
        <briefdescription>
<para>Set the maximum number of steps allowed. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="329" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="329" bodyend="329"/>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1afb8fc975886aa60312d63dff046af34a" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>void RK4</definition>
        <argsstring>(const State &amp;state, const Action &amp;action, arma::vec &amp;dydx, State &amp;nextState)</argsstring>
        <name>RK4</name>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>state</declname>
        </param>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action" kindref="compound">Action</ref> &amp;</type>
          <declname>action</declname>
        </param>
        <param>
          <type>arma::vec &amp;</type>
          <declname>dydx</declname>
        </param>
        <param>
          <type><ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>nextState</declname>
        </param>
        <briefdescription>
<para>This function calls the RK4 iterative method to estimate the next state based on given ordinary differential equation. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>state</parametername>
</parameternamelist>
<parameterdescription>
<para>The current state. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>action</parametername>
</parameternamelist>
<parameterdescription>
<para>The action to be applied. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>dydx</parametername>
</parameternamelist>
<parameterdescription>
<para>The differential. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>nextState</parametername>
</parameternamelist>
<parameterdescription>
<para>The next state. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="238" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="238" bodyend="268"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a3824537c629944975541602c7119a3d9" compoundref="double__pole__cart_8hpp" startline="53" endline="53">DoublePoleCart::State::Data</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1aec6c83f7450927b7520a0c057babc128" compoundref="double__pole__cart_8hpp" startline="197" endline="227">DoublePoleCart::Dsdt</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a790355057d12e9c1ce7643551c16fecd" compoundref="double__pole__cart_8hpp" startline="41" endline="42">DoublePoleCart::State::State</references>
        <referencedby refid="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" compoundref="double__pole__cart_8hpp" startline="159" endline="187">DoublePoleCart::Sample</referencedby>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>double</type>
        <definition>double Sample</definition>
        <argsstring>(const State &amp;state, const Action &amp;action, State &amp;nextState)</argsstring>
        <name>Sample</name>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>state</declname>
        </param>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action" kindref="compound">Action</ref> &amp;</type>
          <declname>action</declname>
        </param>
        <param>
          <type><ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>nextState</declname>
        </param>
        <briefdescription>
<para>Dynamics of Double Pole Cart instance. </para>        </briefdescription>
        <detaileddescription>
<para>Get reward and next state based on current state and current action.</para><para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>state</parametername>
</parameternamelist>
<parameterdescription>
<para>The current state. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>action</parametername>
</parameternamelist>
<parameterdescription>
<para>The current action. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>nextState</parametername>
</parameternamelist>
<parameterdescription>
<para>The next state. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>reward, it&apos;s always 1.0. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
<para>When done is false, it means that the cartpole has fallen down. For this case the reward is 1.0.</para>        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="159" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="159" bodyend="187"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1adee020824f1381e77738134cb3e74c70" compoundref="double__pole__cart_8hpp" startline="73" endline="73">DoublePoleCart::State::AngularVelocity</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1aec6c83f7450927b7520a0c057babc128" compoundref="double__pole__cart_8hpp" startline="197" endline="227">DoublePoleCart::Dsdt</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1a7fd056133dfd315e4bf45c408f99326f" compoundref="double__pole__cart_8hpp" startline="301" endline="321">DoublePoleCart::IsTerminal</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1afb8fc975886aa60312d63dff046af34a" compoundref="double__pole__cart_8hpp" startline="238" endline="268">DoublePoleCart::RK4</references>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State_1a5281cef88d4e272d6cb8581bff91195a" compoundref="double__pole__cart_8hpp" startline="63" endline="63">DoublePoleCart::State::Velocity</references>
        <referencedby refid="classmlpack_1_1rl_1_1DoublePoleCart_1af2bb860eaefeaa62a40f5cf940793704" compoundref="double__pole__cart_8hpp" startline="278" endline="282">DoublePoleCart::Sample</referencedby>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1af2bb860eaefeaa62a40f5cf940793704" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>double</type>
        <definition>double Sample</definition>
        <argsstring>(const State &amp;state, const Action &amp;action)</argsstring>
        <name>Sample</name>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1State" kindref="compound">State</ref> &amp;</type>
          <declname>state</declname>
        </param>
        <param>
          <type>const <ref refid="classmlpack_1_1rl_1_1DoublePoleCart_1_1Action" kindref="compound">Action</ref> &amp;</type>
          <declname>action</declname>
        </param>
        <briefdescription>
<para>Dynamics of Double Pole Cart. </para>        </briefdescription>
        <detaileddescription>
<para>Get reward based on current state and current action.</para><para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>state</parametername>
</parameternamelist>
<parameterdescription>
<para>The current state. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>action</parametername>
</parameternamelist>
<parameterdescription>
<para>The current action. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>reward, it&apos;s always 1.0. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="278" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="278" bodyend="282"/>
        <references refid="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" compoundref="double__pole__cart_8hpp" startline="159" endline="187">DoublePoleCart::Sample</references>
      </memberdef>
      <memberdef kind="function" id="classmlpack_1_1rl_1_1DoublePoleCart_1a5fe06563064ebcee88c593e1673f03d4" prot="public" static="no" const="yes" explicit="no" inline="yes" virt="non-virtual">
        <type>size_t</type>
        <definition>size_t StepsPerformed</definition>
        <argsstring>() const</argsstring>
        <name>StepsPerformed</name>
        <briefdescription>
<para>Get the number of steps performed. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="324" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="324" bodyend="324"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
<para>Implementation of Double Pole Cart Balancing task. </para>    </briefdescription>
    <detaileddescription>
<para>This is an extension of the existing <ref refid="classmlpack_1_1rl_1_1CartPole" kindref="compound">CartPole</ref> environment. The environment comprises of a cart of a cart with two poles of different lengths and masses. The agent is meant to balance the poles by applying force on the cart. </para>    </detaileddescription>
    <location file="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" line="28" column="1" bodyfile="/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/environment/double_pole_cart.hpp" bodystart="27" bodyend="370"/>
    <listofallmembers>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a0c790792348e951b9e3606edc7bb532b" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>doneReward</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a06e56cc33403fd32ffa82a1b7065bd71" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>DoublePoleCart</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1aec6c83f7450927b7520a0c057babc128" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>Dsdt</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1af84c19eb99402801ccb9228ed11c624b" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>forceMag</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a922f2c43a75edbe2ee21ea7ba7b5cb2c" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>gravity</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1aa9f537249fa0c1e62b38197996ab4c6a" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>InitialSample</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a7fd056133dfd315e4bf45c408f99326f" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>IsTerminal</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ad7a541093aca44890413459c6248db6c" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>l1</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1afc8165026561b3471131feeb5a613d1f" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>l2</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a3aa17605b09d35b6df9edb2102876fc5" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>m1</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a59022b29ceaad8397fe7ab1c6041e54e" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>m2</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ad73a528bed94e8954100366adc2134f7" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>massCart</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ac29b91fba0f71e460dee7cf4c503e01a" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>maxSteps</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ad8fd6d8f7581c82e73556491b79a8907" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>MaxSteps</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a64c84cebc489c6fdfd7f057e127b0aef" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>MaxSteps</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1afb8fc975886aa60312d63dff046af34a" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>RK4</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a311ac19edc537dee94f37b7cce93d908" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>Sample</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1af2bb860eaefeaa62a40f5cf940793704" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>Sample</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ae754109e026bb4da3884361bd386d333" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>stepsPerformed</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a5fe06563064ebcee88c593e1673f03d4" prot="public" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>StepsPerformed</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1ae5f7c26321910a384f6f0d37910858a2" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>tau</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a0b053ab37ab8ea4317f303387605fbf1" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>thetaThresholdRadians</name></member>
      <member refid="classmlpack_1_1rl_1_1DoublePoleCart_1a675084def3543d22976ea065dad26f51" prot="private" virt="non-virtual"><scope>mlpack::rl::DoublePoleCart</scope><name>xThreshold</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>
