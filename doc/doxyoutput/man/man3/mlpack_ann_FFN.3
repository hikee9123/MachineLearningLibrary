.TH "FFN< OutputLayerType, InitializationRuleType, CustomLayers >" 3 "Sun Aug 22 2021" "Version 3.4.2" "mlpack" \" -*- nroff -*-
.ad l
.nh
.SH NAME
FFN< OutputLayerType, InitializationRuleType, CustomLayers > \- Implementation of a standard feed forward network\&.  

.SH SYNOPSIS
.br
.PP
.SS "Public Types"

.in +1c
.ti -1c
.RI "using \fBNetworkType\fP = \fBFFN\fP< OutputLayerType, InitializationRuleType >"
.br
.RI "Convenience typedef for the internal model construction\&. "
.in -1c
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "\fBFFN\fP (OutputLayerType outputLayer=OutputLayerType(), InitializationRuleType initializeRule=InitializationRuleType())"
.br
.RI "Create the \fBFFN\fP object\&. "
.ti -1c
.RI "\fBFFN\fP (const \fBFFN\fP &)"
.br
.RI "Copy constructor\&. "
.ti -1c
.RI "\fBFFN\fP (\fBFFN\fP &&)"
.br
.RI "Move constructor\&. "
.ti -1c
.RI "\fB~FFN\fP ()"
.br
.RI "Destructor to release allocated memory\&. "
.ti -1c
.RI "template<class LayerType , class\&.\&.\&. Args> void \fBAdd\fP (Args\&.\&.\&. args)"
.br
.ti -1c
.RI "void \fBAdd\fP (\fBLayerTypes\fP< CustomLayers\&.\&.\&. > layer)"
.br
.ti -1c
.RI "template<typename PredictorsType , typename TargetsType , typename GradientsType > double \fBBackward\fP (const PredictorsType &inputs, const TargetsType &targets, GradientsType &gradients)"
.br
.RI "Perform the backward pass of the data in real batch mode\&. "
.ti -1c
.RI "template<typename PredictorsType , typename ResponsesType > double \fBEvaluate\fP (const PredictorsType &predictors, const ResponsesType &responses)"
.br
.RI "Evaluate the feedforward network with the given predictors and responses\&. "
.ti -1c
.RI "double \fBEvaluate\fP (const arma::mat &parameters)"
.br
.RI "Evaluate the feedforward network with the given parameters\&. "
.ti -1c
.RI "double \fBEvaluate\fP (const arma::mat &parameters, const size_t begin, const size_t batchSize, const bool deterministic)"
.br
.RI "Evaluate the feedforward network with the given parameters, but using only a number of data points\&. "
.ti -1c
.RI "double \fBEvaluate\fP (const arma::mat &parameters, const size_t begin, const size_t batchSize)"
.br
.RI "Evaluate the feedforward network with the given parameters, but using only a number of data points\&. "
.ti -1c
.RI "template<typename GradType > double \fBEvaluateWithGradient\fP (const arma::mat &parameters, GradType &gradient)"
.br
.RI "Evaluate the feedforward network with the given parameters\&. "
.ti -1c
.RI "template<typename GradType > double \fBEvaluateWithGradient\fP (const arma::mat &parameters, const size_t begin, GradType &gradient, const size_t batchSize)"
.br
.RI "Evaluate the feedforward network with the given parameters, but using only a number of data points\&. "
.ti -1c
.RI "template<typename PredictorsType , typename ResponsesType > void \fBForward\fP (const PredictorsType &inputs, ResponsesType &results)"
.br
.RI "Perform the forward pass of the data in real batch mode\&. "
.ti -1c
.RI "template<typename PredictorsType , typename ResponsesType > void \fBForward\fP (const PredictorsType &inputs, ResponsesType &results, const size_t begin, const size_t end)"
.br
.RI "Perform a partial forward pass of the data\&. "
.ti -1c
.RI "void \fBGradient\fP (const arma::mat &parameters, const size_t begin, arma::mat &gradient, const size_t batchSize)"
.br
.RI "Evaluate the gradient of the feedforward network with the given parameters, and with respect to only a number of points in the dataset\&. "
.ti -1c
.RI "const std::vector< \fBLayerTypes\fP< CustomLayers\&.\&.\&. > > & \fBModel\fP () const"
.br
.RI "Get the network model\&. "
.ti -1c
.RI "std::vector< \fBLayerTypes\fP< CustomLayers\&.\&.\&. > > & \fBModel\fP ()"
.br
.RI "Modify the network model\&. "
.ti -1c
.RI "size_t \fBNumFunctions\fP () const"
.br
.RI "Return the number of separable functions (the number of predictor points)\&. "
.ti -1c
.RI "\fBFFN\fP & \fBoperator=\fP (\fBFFN\fP)"
.br
.RI "Copy/move assignment operator\&. "
.ti -1c
.RI "const arma::mat & \fBParameters\fP () const"
.br
.RI "Return the initial point for the optimization\&. "
.ti -1c
.RI "arma::mat & \fBParameters\fP ()"
.br
.RI "Modify the initial point for the optimization\&. "
.ti -1c
.RI "void \fBPredict\fP (arma::mat predictors, arma::mat &results)"
.br
.RI "Predict the responses to a given set of predictors\&. "
.ti -1c
.RI "const arma::mat & \fBPredictors\fP () const"
.br
.RI "Get the matrix of data points (predictors)\&. "
.ti -1c
.RI "arma::mat & \fBPredictors\fP ()"
.br
.RI "Modify the matrix of data points (predictors)\&. "
.ti -1c
.RI "void \fBResetParameters\fP ()"
.br
.RI "Reset the module infomration (weights/parameters)\&. "
.ti -1c
.RI "const arma::mat & \fBResponses\fP () const"
.br
.RI "Get the matrix of responses to the input data points\&. "
.ti -1c
.RI "arma::mat & \fBResponses\fP ()"
.br
.RI "Modify the matrix of responses to the input data points\&. "
.ti -1c
.RI "template<typename Archive > void \fBserialize\fP (Archive &ar, const uint32_t)"
.br
.RI "Serialize the model\&. "
.ti -1c
.RI "void \fBShuffle\fP ()"
.br
.RI "Shuffle the order of function visitation\&. "
.ti -1c
.RI "template<typename OptimizerType , typename\&.\&.\&. CallbackTypes> double \fBTrain\fP (arma::mat predictors, arma::mat responses, OptimizerType &optimizer, CallbackTypes &&\&.\&.\&. callbacks)"
.br
.RI "Train the feedforward network on the given input data using the given optimizer\&. "
.ti -1c
.RI "template<typename OptimizerType  = ens::RMSProp, typename\&.\&.\&. CallbackTypes> double \fBTrain\fP (arma::mat predictors, arma::mat responses, CallbackTypes &&\&.\&.\&. callbacks)"
.br
.RI "Train the feedforward network on the given input data\&. "
.ti -1c
.RI "template<typename OptimizerType > std::enable_if< HasMaxIterations< OptimizerType, size_t &(OptimizerType::*)()>::value, void >::type \fBWarnMessageMaxIterations\fP (OptimizerType &optimizer, size_t samples) const"
.br
.RI "Check if the optimizer has MaxIterations() parameter, if it does then check if it's value is less than the number of datapoints in the dataset\&. "
.ti -1c
.RI "template<typename OptimizerType > std::enable_if< !HasMaxIterations< OptimizerType, size_t &(OptimizerType::*)()>::value, void >::type \fBWarnMessageMaxIterations\fP (OptimizerType &optimizer, size_t samples) const"
.br
.RI "Check if the optimizer has MaxIterations() parameter, if it doesn't then simply return from the function\&. "
.in -1c
.SH "Detailed Description"
.PP 

.SS "template<typename OutputLayerType = NegativeLogLikelihood<>, typename InitializationRuleType = RandomInitialization, typename\&.\&.\&. CustomLayers>
.br
class mlpack::ann::FFN< OutputLayerType, InitializationRuleType, CustomLayers >"
Implementation of a standard feed forward network\&. 


.PP
\fBTemplate Parameters:\fP
.RS 4
\fIOutputLayerType\fP The output layer type used to evaluate the network\&. 
.br
\fIInitializationRuleType\fP Rule used to initialize the weight matrix\&. 
.br
\fICustomLayers\fP Any set of custom layers that could be a part of the feed forward network\&. 
.RE
.PP

.PP
Definition at line 52 of file ffn\&.hpp\&.
.SH "Member Typedef Documentation"
.PP 
.SS "using \fBNetworkType\fP =  \fBFFN\fP<OutputLayerType, InitializationRuleType>"

.PP
Convenience typedef for the internal model construction\&. 
.PP
Definition at line 56 of file ffn\&.hpp\&.
.SH "Constructor & Destructor Documentation"
.PP 
.SS "\fBFFN\fP (OutputLayerType outputLayer = \fCOutputLayerType()\fP, InitializationRuleType initializeRule = \fCInitializationRuleType()\fP)"

.PP
Create the \fBFFN\fP object\&. Optionally, specify which initialize rule and performance function should be used\&.
.PP
If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy\&.
.PP
\fBParameters:\fP
.RS 4
\fIoutputLayer\fP Output layer used to evaluate the network\&. 
.br
\fIinitializeRule\fP Optional instantiated InitializationRule object for initializing the network parameter\&. 
.RE
.PP

.SS "\fBFFN\fP (const \fBFFN\fP< OutputLayerType, InitializationRuleType, CustomLayers > &)"

.PP
Copy constructor\&. 
.SS "\fBFFN\fP (\fBFFN\fP< OutputLayerType, InitializationRuleType, CustomLayers > &&)"

.PP
Move constructor\&. 
.SS "~\fBFFN\fP ()"

.PP
Destructor to release allocated memory\&. 
.SH "Member Function Documentation"
.PP 
.SS "void \fBAdd\fP (Args\&.\&.\&. args)\fC [inline]\fP"

.PP
Definition at line 290 of file ffn\&.hpp\&.
.SS "void \fBAdd\fP (\fBLayerTypes\fP< CustomLayers\&.\&.\&. > layer)\fC [inline]\fP"

.PP
Definition at line 297 of file ffn\&.hpp\&.
.SS "double Backward (const PredictorsType & inputs, const TargetsType & targets, GradientsType & gradients)"

.PP
Perform the backward pass of the data in real batch mode\&. Forward and Backward should be used as a pair, and they are designed mainly for advanced users\&. User should try to use Predict and Train unless those two functions can't satisfy some special requirements\&.
.PP
\fBParameters:\fP
.RS 4
\fIinputs\fP Inputs of current pass\&. 
.br
\fItargets\fP The training target\&. 
.br
\fIgradients\fP Computed gradients\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
Training error of the current pass\&. 
.RE
.PP

.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "double Evaluate (const PredictorsType & predictors, const ResponsesType & responses)"

.PP
Evaluate the feedforward network with the given predictors and responses\&. This functions is usually used to monitor progress while training\&.
.PP
\fBParameters:\fP
.RS 4
\fIpredictors\fP Input variables\&. 
.br
\fIresponses\fP Target outputs for input variables\&. 
.RE
.PP

.SS "double Evaluate (const arma::mat & parameters)"

.PP
Evaluate the feedforward network with the given parameters\&. This function is usually called by the optimizer to train the model\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix model parameters\&. 
.RE
.PP

.SS "double Evaluate (const arma::mat & parameters, const size_t begin, const size_t batchSize, const bool deterministic)"

.PP
Evaluate the feedforward network with the given parameters, but using only a number of data points\&. This is useful for optimizers such as SGD, which require a separable objective function\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix model parameters\&. 
.br
\fIbegin\fP Index of the starting point to use for objective function evaluation\&. 
.br
\fIbatchSize\fP Number of points to be passed at a time to use for objective function evaluation\&. 
.br
\fIdeterministic\fP Whether or not to train or test the model\&. Note some layer act differently in training or testing mode\&. 
.RE
.PP

.SS "double Evaluate (const arma::mat & parameters, const size_t begin, const size_t batchSize)"

.PP
Evaluate the feedforward network with the given parameters, but using only a number of data points\&. This is useful for optimizers such as SGD, which require a separable objective function\&. This just calls the overload of \fBEvaluate()\fP with deterministic = true\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix model parameters\&. 
.br
\fIbegin\fP Index of the starting point to use for objective function evaluation\&. 
.br
\fIbatchSize\fP Number of points to be passed at a time to use for objective function evaluation\&. 
.RE
.PP

.SS "double EvaluateWithGradient (const arma::mat & parameters, GradType & gradient)"

.PP
Evaluate the feedforward network with the given parameters\&. This function is usually called by the optimizer to train the model\&. This just calls the overload of \fBEvaluateWithGradient()\fP with batchSize = 1\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix model parameters\&. 
.br
\fIgradient\fP Matrix to output gradient into\&. 
.RE
.PP

.SS "double EvaluateWithGradient (const arma::mat & parameters, const size_t begin, GradType & gradient, const size_t batchSize)"

.PP
Evaluate the feedforward network with the given parameters, but using only a number of data points\&. This is useful for optimizers such as SGD, which require a separable objective function\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix model parameters\&. 
.br
\fIbegin\fP Index of the starting point to use for objective function evaluation\&. 
.br
\fIgradient\fP Matrix to output gradient into\&. 
.br
\fIbatchSize\fP Number of points to be passed at a time to use for objective function evaluation\&. 
.RE
.PP

.SS "void Forward (const PredictorsType & inputs, ResponsesType & results)"

.PP
Perform the forward pass of the data in real batch mode\&. Forward and Backward should be used as a pair, and they are designed mainly for advanced users\&. User should try to use Predict and Train unless those two functions can't satisfy some special requirements\&.
.PP
\fBParameters:\fP
.RS 4
\fIinputs\fP The input data\&. 
.br
\fIresults\fP The predicted results\&. 
.RE
.PP

.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "void Forward (const PredictorsType & inputs, ResponsesType & results, const size_t begin, const size_t end)"

.PP
Perform a partial forward pass of the data\&. This function is meant for the cases when users require a forward pass only through certain layers and not the entire network\&.
.PP
\fBParameters:\fP
.RS 4
\fIinputs\fP The input data for the specified first layer\&. 
.br
\fIresults\fP The predicted results from the specified last layer\&. 
.br
\fIbegin\fP The index of the first layer\&. 
.br
\fIend\fP The index of the last layer\&. 
.RE
.PP

.SS "void Gradient (const arma::mat & parameters, const size_t begin, arma::mat & gradient, const size_t batchSize)"

.PP
Evaluate the gradient of the feedforward network with the given parameters, and with respect to only a number of points in the dataset\&. This is useful for optimizers such as SGD, which require a separable objective function\&.
.PP
\fBParameters:\fP
.RS 4
\fIparameters\fP Matrix of the model parameters to be optimized\&. 
.br
\fIbegin\fP Index of the starting point to use for objective function gradient evaluation\&. 
.br
\fIgradient\fP Matrix to output gradient into\&. 
.br
\fIbatchSize\fP Number of points to be processed as a batch for objective function gradient evaluation\&. 
.RE
.PP

.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "const std::vector<\fBLayerTypes\fP<CustomLayers\&.\&.\&.> >& Model () const\fC [inline]\fP"

.PP
Get the network model\&. 
.PP
Definition at line 300 of file ffn\&.hpp\&.
.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "std::vector<\fBLayerTypes\fP<CustomLayers\&.\&.\&.> >& Model ()\fC [inline]\fP"

.PP
Modify the network model\&. Be careful! If you change the structure of the network or parameters for layers, its state may become invalid, so be sure to call \fBResetParameters()\fP afterwards\&. 
.PP
Definition at line 307 of file ffn\&.hpp\&.
.SS "size_t NumFunctions () const\fC [inline]\fP"

.PP
Return the number of separable functions (the number of predictor points)\&. 
.PP
Definition at line 310 of file ffn\&.hpp\&.
.SS "\fBFFN\fP& operator= (\fBFFN\fP< OutputLayerType, InitializationRuleType, CustomLayers >)"

.PP
Copy/move assignment operator\&. 
.SS "const arma::mat& Parameters () const\fC [inline]\fP"

.PP
Return the initial point for the optimization\&. 
.PP
Definition at line 313 of file ffn\&.hpp\&.
.SS "arma::mat& Parameters ()\fC [inline]\fP"

.PP
Modify the initial point for the optimization\&. 
.PP
Definition at line 315 of file ffn\&.hpp\&.
.SS "void Predict (arma::mat predictors, arma::mat & results)"

.PP
Predict the responses to a given set of predictors\&. The responses will reflect the output of the given output layer as returned by the output layer function\&.
.PP
If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy\&.
.PP
\fBParameters:\fP
.RS 4
\fIpredictors\fP Input predictors\&. 
.br
\fIresults\fP Matrix to put output predictions of responses into\&. 
.RE
.PP

.SS "const arma::mat& Predictors () const\fC [inline]\fP"

.PP
Get the matrix of data points (predictors)\&. 
.PP
Definition at line 323 of file ffn\&.hpp\&.
.SS "arma::mat& Predictors ()\fC [inline]\fP"

.PP
Modify the matrix of data points (predictors)\&. 
.PP
Definition at line 325 of file ffn\&.hpp\&.
.PP
References FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Backward(), FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Forward(), FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Gradient(), FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Model(), FFN< OutputLayerType, InitializationRuleType, CustomLayers >::ResetParameters(), and FFN< OutputLayerType, InitializationRuleType, CustomLayers >::serialize()\&.
.SS "void ResetParameters ()"

.PP
Reset the module infomration (weights/parameters)\&. 
.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "const arma::mat& Responses () const\fC [inline]\fP"

.PP
Get the matrix of responses to the input data points\&. 
.PP
Definition at line 318 of file ffn\&.hpp\&.
.SS "arma::mat& Responses ()\fC [inline]\fP"

.PP
Modify the matrix of responses to the input data points\&. 
.PP
Definition at line 320 of file ffn\&.hpp\&.
.SS "void serialize (Archive & ar, const uint32_t)"

.PP
Serialize the model\&. 
.PP
Referenced by FFN< OutputLayerType, InitializationRuleType, CustomLayers >::Predictors()\&.
.SS "void Shuffle ()"

.PP
Shuffle the order of function visitation\&. This may be called by the optimizer\&. 
.SS "double Train (arma::mat predictors, arma::mat responses, OptimizerType & optimizer, CallbackTypes &&\&.\&.\&. callbacks)"

.PP
Train the feedforward network on the given input data using the given optimizer\&. This will use the existing model parameters as a starting point for the optimization\&. If this is not what you want, then you should access the parameters vector directly with \fBParameters()\fP and modify it as desired\&.
.PP
If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy\&.
.PP
\fBTemplate Parameters:\fP
.RS 4
\fIOptimizerType\fP Type of optimizer to use to train the model\&. 
.br
\fICallbackTypes\fP Types of Callback Functions\&. 
.RE
.PP
\fBParameters:\fP
.RS 4
\fIpredictors\fP Input training variables\&. 
.br
\fIresponses\fP Outputs results from input training variables\&. 
.br
\fIoptimizer\fP Instantiated optimizer used to train the model\&. 
.br
\fIcallbacks\fP Callback function for ensmallen optimizer \fCOptimizerType\fP\&. See https://www.ensmallen.org/docs.html#callback-documentation\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
The final objective of the trained model (NaN or Inf on error)\&. 
.RE
.PP

.SS "double Train (arma::mat predictors, arma::mat responses, CallbackTypes &&\&.\&.\&. callbacks)"

.PP
Train the feedforward network on the given input data\&. By default, the RMSProp optimization algorithm is used, but others can be specified (such as ens::SGD)\&.
.PP
This will use the existing model parameters as a starting point for the optimization\&. If this is not what you want, then you should access the parameters vector directly with \fBParameters()\fP and modify it as desired\&.
.PP
If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy\&.
.PP
\fBTemplate Parameters:\fP
.RS 4
\fIOptimizerType\fP Type of optimizer to use to train the model\&. 
.RE
.PP
\fBParameters:\fP
.RS 4
\fIpredictors\fP Input training variables\&. 
.RE
.PP
\fBTemplate Parameters:\fP
.RS 4
\fICallbackTypes\fP Types of Callback Functions\&. 
.RE
.PP
\fBParameters:\fP
.RS 4
\fIresponses\fP Outputs results from input training variables\&. 
.br
\fIcallbacks\fP Callback function for ensmallen optimizer \fCOptimizerType\fP\&. See https://www.ensmallen.org/docs.html#callback-documentation\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
The final objective of the trained model (NaN or Inf on error)\&. 
.RE
.PP

.SS "std::enable_if< HasMaxIterations<OptimizerType, size_t&(OptimizerType::*)()>::value, void>::type WarnMessageMaxIterations (OptimizerType & optimizer, size_t samples) const"

.PP
Check if the optimizer has MaxIterations() parameter, if it does then check if it's value is less than the number of datapoints in the dataset\&. 
.PP
\fBTemplate Parameters:\fP
.RS 4
\fIOptimizerType\fP Type of optimizer to use to train the model\&. 
.RE
.PP
\fBParameters:\fP
.RS 4
\fIoptimizer\fP optimizer used in the training process\&. 
.br
\fIsamples\fP Number of datapoints in the dataset\&. 
.RE
.PP

.SS "std::enable_if< !HasMaxIterations<OptimizerType, size_t&(OptimizerType::*)()>::value, void>::type WarnMessageMaxIterations (OptimizerType & optimizer, size_t samples) const"

.PP
Check if the optimizer has MaxIterations() parameter, if it doesn't then simply return from the function\&. 
.PP
\fBTemplate Parameters:\fP
.RS 4
\fIOptimizerType\fP Type of optimizer to use to train the model\&. 
.RE
.PP
\fBParameters:\fP
.RS 4
\fIoptimizer\fP optimizer used in the training process\&. 
.br
\fIsamples\fP Number of datapoints in the dataset\&. 
.RE
.PP


.SH "Author"
.PP 
Generated automatically by Doxygen for mlpack from the source code\&.
