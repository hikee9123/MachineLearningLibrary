\section{Linear\+Regression Class Reference}
\label{classmlpack_1_1regression_1_1LinearRegression}\index{Linear\+Regression@{Linear\+Regression}}


A simple linear regression algorithm using ordinary least squares.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Linear\+Regression} (const arma\+::mat \&predictors, const arma\+::rowvec \&responses, const double lambda=0, const bool intercept=true)
\begin{DoxyCompactList}\small\item\em Creates the model. \end{DoxyCompactList}\item 
\textbf{ Linear\+Regression} (const arma\+::mat \&predictors, const arma\+::rowvec \&responses, const arma\+::rowvec \&weights, const double lambda=0, const bool intercept=true)
\begin{DoxyCompactList}\small\item\em Creates the model with weighted learning. \end{DoxyCompactList}\item 
\textbf{ Linear\+Regression} ()
\begin{DoxyCompactList}\small\item\em Empty constructor. \end{DoxyCompactList}\item 
double \textbf{ Compute\+Error} (const arma\+::mat \&points, const arma\+::rowvec \&responses) const
\begin{DoxyCompactList}\small\item\em Calculate the L2 squared error on the given predictors and responses using this linear regression model. \end{DoxyCompactList}\item 
bool \textbf{ Intercept} () const
\begin{DoxyCompactList}\small\item\em Return whether or not an intercept term is used in the model. \end{DoxyCompactList}\item 
double \textbf{ Lambda} () const
\begin{DoxyCompactList}\small\item\em Return the Tikhonov regularization parameter for ridge regression. \end{DoxyCompactList}\item 
double \& \textbf{ Lambda} ()
\begin{DoxyCompactList}\small\item\em Modify the Tikhonov regularization parameter for ridge regression. \end{DoxyCompactList}\item 
const arma\+::vec \& \textbf{ Parameters} () const
\begin{DoxyCompactList}\small\item\em Return the parameters (the b vector). \end{DoxyCompactList}\item 
arma\+::vec \& \textbf{ Parameters} ()
\begin{DoxyCompactList}\small\item\em Modify the parameters (the b vector). \end{DoxyCompactList}\item 
void \textbf{ Predict} (const arma\+::mat \&points, arma\+::rowvec \&predictions) const
\begin{DoxyCompactList}\small\item\em Calculate y\+\_\+i for each data point in points. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void \textbf{ serialize} (Archive \&ar, const uint32\+\_\+t)
\begin{DoxyCompactList}\small\item\em Serialize the model. \end{DoxyCompactList}\item 
double \textbf{ Train} (const arma\+::mat \&predictors, const arma\+::rowvec \&responses, const bool intercept=true)
\begin{DoxyCompactList}\small\item\em Train the \doxyref{Linear\+Regression}{p.}{classmlpack_1_1regression_1_1LinearRegression} model on the given data. \end{DoxyCompactList}\item 
double \textbf{ Train} (const arma\+::mat \&predictors, const arma\+::rowvec \&responses, const arma\+::rowvec \&weights, const bool intercept=true)
\begin{DoxyCompactList}\small\item\em Train the \doxyref{Linear\+Regression}{p.}{classmlpack_1_1regression_1_1LinearRegression} model on the given data and weights. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
A simple linear regression algorithm using ordinary least squares. 

Optionally, this class can perform ridge regression, if the lambda parameter is set to a number greater than zero. 

Definition at line 26 of file linear\+\_\+regression.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a5512c52fafc771cd94e1ae8ea65d1729}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Linear\+Regression@{Linear\+Regression}}
\index{Linear\+Regression@{Linear\+Regression}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Linear\+Regression()\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily \textbf{ Linear\+Regression} (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::rowvec \&}]{responses,  }\item[{const double}]{lambda = {\ttfamily 0},  }\item[{const bool}]{intercept = {\ttfamily true} }\end{DoxyParamCaption})}



Creates the model. 


\begin{DoxyParams}{Parameters}
{\em predictors} & X, matrix of data points. \\
\hline
{\em responses} & y, the measured data for each point in X. \\
\hline
{\em lambda} & Regularization constant for ridge regression. \\
\hline
{\em intercept} & Whether or not to include an intercept term. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a038242ee2c6c66ef9e287503fffe64e9}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Linear\+Regression@{Linear\+Regression}}
\index{Linear\+Regression@{Linear\+Regression}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Linear\+Regression()\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily \textbf{ Linear\+Regression} (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::rowvec \&}]{responses,  }\item[{const arma\+::rowvec \&}]{weights,  }\item[{const double}]{lambda = {\ttfamily 0},  }\item[{const bool}]{intercept = {\ttfamily true} }\end{DoxyParamCaption})}



Creates the model with weighted learning. 


\begin{DoxyParams}{Parameters}
{\em predictors} & X, matrix of data points. \\
\hline
{\em responses} & y, the measured data for each point in X. \\
\hline
{\em weights} & Observation weights (for boosting). \\
\hline
{\em lambda} & Regularization constant for ridge regression. \\
\hline
{\em intercept} & Whether or not to include an intercept term. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a33f04840f1f440c8ab14254ce127cf9f}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Linear\+Regression@{Linear\+Regression}}
\index{Linear\+Regression@{Linear\+Regression}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Linear\+Regression()\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily \textbf{ Linear\+Regression} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Empty constructor. 

This gives a non-\/working model, so make sure \doxyref{Train()}{p.}{classmlpack_1_1regression_1_1LinearRegression_a593683fefbb596f9b7f6347d0be5a562} is called (or make sure the model parameters are set) before calling \doxyref{Predict()}{p.}{classmlpack_1_1regression_1_1LinearRegression_a71e5e21b1d92756979b32face7b3c573}! 

Definition at line 62 of file linear\+\_\+regression.\+hpp.



References Linear\+Regression\+::\+Compute\+Error(), Linear\+Regression\+::\+Predict(), and Linear\+Regression\+::\+Train().



\subsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_ad1b012d8c3cad8c6a155b715cb32a134}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Compute\+Error@{Compute\+Error}}
\index{Compute\+Error@{Compute\+Error}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Compute\+Error()}
{\footnotesize\ttfamily double Compute\+Error (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{points,  }\item[{const arma\+::rowvec \&}]{responses }\end{DoxyParamCaption}) const}



Calculate the L2 squared error on the given predictors and responses using this linear regression model. 

This calculation returns

\[ (1 / n) * \| y - X B \|^2_2 \]

where $ y $ is the responses vector, $ X $ is the matrix of predictors, and $ B $ is the parameters of the trained linear regression model.

As this number decreases to 0, the linear regression fit is better.


\begin{DoxyParams}{Parameters}
{\em points} & Matrix of predictors (X). \\
\hline
{\em responses} & Transposed vector of responses (y$^\wedge$T). \\
\hline
\end{DoxyParams}


Referenced by Linear\+Regression\+::\+Linear\+Regression().

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_aa755a6a1366c3ba88bb0f8543127ccea}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Intercept@{Intercept}}
\index{Intercept@{Intercept}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Intercept()}
{\footnotesize\ttfamily bool Intercept (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return whether or not an intercept term is used in the model. 



Definition at line 137 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a53535041275cedd0ec3de67ca032aa94}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Lambda()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Lambda (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return the Tikhonov regularization parameter for ridge regression. 



Definition at line 132 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_aaf66629b989a326453647f42443c6a0c}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Lambda()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double\& Lambda (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the Tikhonov regularization parameter for ridge regression. 



Definition at line 134 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a6a67e9b83bb8f0ea6122efcc5f75927c}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const arma\+::vec\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return the parameters (the b vector). 



Definition at line 127 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a6c16a2172d1b0486c8677bba4c5a3ff1}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily arma\+::vec\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the parameters (the b vector). 



Definition at line 129 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a71e5e21b1d92756979b32face7b3c573}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Predict@{Predict}}
\index{Predict@{Predict}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Predict()}
{\footnotesize\ttfamily void Predict (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{points,  }\item[{arma\+::rowvec \&}]{predictions }\end{DoxyParamCaption}) const}



Calculate y\+\_\+i for each data point in points. 


\begin{DoxyParams}{Parameters}
{\em points} & the data points to calculate with. \\
\hline
{\em predictions} & y, will contain calculated values on completion. \\
\hline
\end{DoxyParams}


Referenced by Linear\+Regression\+::\+Linear\+Regression().

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a65cba07328997659bec80b9879b15a51}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!serialize@{serialize}}
\index{serialize@{serialize}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{serialize()}
{\footnotesize\ttfamily void serialize (\begin{DoxyParamCaption}\item[{Archive \&}]{ar,  }\item[{const uint32\+\_\+t}]{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Serialize the model. 



Definition at line 143 of file linear\+\_\+regression.\+hpp.

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_a593683fefbb596f9b7f6347d0be5a562}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Train@{Train}}
\index{Train@{Train}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Train()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Train (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::rowvec \&}]{responses,  }\item[{const bool}]{intercept = {\ttfamily true} }\end{DoxyParamCaption})}



Train the \doxyref{Linear\+Regression}{p.}{classmlpack_1_1regression_1_1LinearRegression} model on the given data. 

Careful! This will completely ignore and overwrite the existing model. This particular implementation does not have an incremental training algorithm. To set the regularization parameter lambda, call \doxyref{Lambda()}{p.}{classmlpack_1_1regression_1_1LinearRegression_aaf66629b989a326453647f42443c6a0c} or set a different value in the constructor.


\begin{DoxyParams}{Parameters}
{\em predictors} & X, the matrix of data points to train the model on. \\
\hline
{\em responses} & y, the responses to the data points. \\
\hline
{\em intercept} & Whether or not to fit an intercept term. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The least squares error after training. 
\end{DoxyReturn}


Referenced by Linear\+Regression\+::\+Linear\+Regression().

\mbox{\label{classmlpack_1_1regression_1_1LinearRegression_aae707a6e9fb9f1958a70f8a078135eef}} 
\index{mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}!Train@{Train}}
\index{Train@{Train}!mlpack\+::regression\+::\+Linear\+Regression@{mlpack\+::regression\+::\+Linear\+Regression}}
\subsubsection{Train()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Train (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{predictors,  }\item[{const arma\+::rowvec \&}]{responses,  }\item[{const arma\+::rowvec \&}]{weights,  }\item[{const bool}]{intercept = {\ttfamily true} }\end{DoxyParamCaption})}



Train the \doxyref{Linear\+Regression}{p.}{classmlpack_1_1regression_1_1LinearRegression} model on the given data and weights. 

Careful! This will completely ignore and overwrite the existing model. This particular implementation does not have an incremental training algorithm. To set the regularization parameter lambda, call \doxyref{Lambda()}{p.}{classmlpack_1_1regression_1_1LinearRegression_aaf66629b989a326453647f42443c6a0c} or set a different value in the constructor.


\begin{DoxyParams}{Parameters}
{\em predictors} & X, the matrix of data points to train the model on. \\
\hline
{\em responses} & y, the responses to the data points. \\
\hline
{\em weights} & Observation weights (for boosting). \\
\hline
{\em intercept} & Whether or not to fit an intercept term. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The least squares error after training. 
\end{DoxyReturn}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/linear\+\_\+regression/\textbf{ linear\+\_\+regression.\+hpp}\end{DoxyCompactItemize}
