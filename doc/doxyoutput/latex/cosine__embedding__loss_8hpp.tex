\section{/home/aakash/mlpack/src/mlpack/methods/ann/loss\+\_\+functions/cosine\+\_\+embedding\+\_\+loss.hpp File Reference}
\label{cosine__embedding__loss_8hpp}\index{/home/aakash/mlpack/src/mlpack/methods/ann/loss\+\_\+functions/cosine\+\_\+embedding\+\_\+loss.\+hpp@{/home/aakash/mlpack/src/mlpack/methods/ann/loss\+\_\+functions/cosine\+\_\+embedding\+\_\+loss.\+hpp}}
Include dependency graph for cosine\+\_\+embedding\+\_\+loss.\+hpp\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{cosine__embedding__loss_8hpp__incl}
\end{center}
\end{figure}
\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \textbf{ Cosine\+Embedding\+Loss$<$ Input\+Data\+Type, Output\+Data\+Type $>$}
\begin{DoxyCompactList}\small\item\em Cosine Embedding Loss function is used for measuring whether two inputs are similar or dissimilar, using the cosine distance, and is typically used for learning nonlinear embeddings or semi-\/supervised learning. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
 \textbf{ mlpack}
\begin{DoxyCompactList}\small\item\em Linear algebra utility functions, generally performed on matrices or vectors. \end{DoxyCompactList}\item 
 \textbf{ mlpack\+::ann}
\begin{DoxyCompactList}\small\item\em Artificial Neural Network. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyAuthor}{Author}
Kartik Dutt
\end{DoxyAuthor}
Definition of the Cosine Embedding loss function.

mlpack is free software; you may redistribute it and/or modify it under the terms of the 3-\/clause B\+SD license. You should have received a copy of the 3-\/clause B\+SD license along with mlpack. If not, see {\tt http\+://www.\+opensource.\+org/licenses/\+B\+S\+D-\/3-\/\+Clause} for more information. 