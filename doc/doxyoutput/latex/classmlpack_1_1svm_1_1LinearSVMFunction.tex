\section{Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$ Class Template Reference}
\label{classmlpack_1_1svm_1_1LinearSVMFunction}\index{Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$@{Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$}}


The hinge loss function for the linear S\+VM objective function.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Linear\+S\+V\+M\+Function} (const Mat\+Type \&dataset, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, const size\+\_\+t num\+Classes, const double lambda=0.\+0001, const double delta=1.\+0, const bool fit\+Intercept=false)
\begin{DoxyCompactList}\small\item\em Construct the Linear S\+VM objective function with given parameters. \end{DoxyCompactList}\item 
const arma\+::sp\+\_\+mat \& \textbf{ Dataset} () const
\begin{DoxyCompactList}\small\item\em Get the dataset. \end{DoxyCompactList}\item 
arma\+::sp\+\_\+mat \& \textbf{ Dataset} ()
\begin{DoxyCompactList}\small\item\em Modify the dataset. \end{DoxyCompactList}\item 
double \textbf{ Evaluate} (const arma\+::mat \&parameters)
\begin{DoxyCompactList}\small\item\em Evaluate the hinge loss function for all the datapoints. \end{DoxyCompactList}\item 
double \textbf{ Evaluate} (const arma\+::mat \&parameters, const size\+\_\+t first\+Id, const size\+\_\+t batch\+Size=1)
\begin{DoxyCompactList}\small\item\em Evaluate the hinge loss function on the specified datapoints. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\double \textbf{ Evaluate\+With\+Gradient} (const arma\+::mat \&parameters, Grad\+Type \&gradient) const
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function followed by evaluation of the hinge loss function on all the datapoints. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\double \textbf{ Evaluate\+With\+Gradient} (const arma\+::mat \&parameters, const size\+\_\+t first\+Id, Grad\+Type \&gradient, const size\+\_\+t batch\+Size=1) const
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function followed by evaluation of the hinge loss function on the specified datapoints. \end{DoxyCompactList}\item 
bool \textbf{ Fit\+Intercept} () const
\begin{DoxyCompactList}\small\item\em Gets the intercept flag. \end{DoxyCompactList}\item 
void \textbf{ Get\+Ground\+Truth\+Matrix} (const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, arma\+::sp\+\_\+mat \&ground\+Truth)
\begin{DoxyCompactList}\small\item\em Constructs the ground truth label matrix with the passed labels. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\void \textbf{ Gradient} (const arma\+::mat \&parameters, Grad\+Type \&gradient)
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the hinge loss function following the Linear\+Function\+Type requirements on the Gradient function. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\void \textbf{ Gradient} (const arma\+::mat \&parameters, const size\+\_\+t first\+Id, Grad\+Type \&gradient, const size\+\_\+t batch\+Size=1)
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function. \end{DoxyCompactList}\item 
const arma\+::mat \& \textbf{ Initial\+Point} () const
\begin{DoxyCompactList}\small\item\em Return the initial point for the optimization. \end{DoxyCompactList}\item 
arma\+::mat \& \textbf{ Initial\+Point} ()
\begin{DoxyCompactList}\small\item\em Modify the initial point for the optimization. \end{DoxyCompactList}\item 
double \& \textbf{ Lambda} ()
\begin{DoxyCompactList}\small\item\em Sets the regularization parameter. \end{DoxyCompactList}\item 
double \textbf{ Lambda} () const
\begin{DoxyCompactList}\small\item\em Gets the regularization parameter. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Num\+Functions} () const
\begin{DoxyCompactList}\small\item\em Return the number of functions. \end{DoxyCompactList}\item 
void \textbf{ Shuffle} ()
\begin{DoxyCompactList}\small\item\em Shuffle the dataset. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
static void \textbf{ Initialize\+Weights} (arma\+::mat \&weights, const size\+\_\+t feature\+Size, const size\+\_\+t num\+Classes, const bool fit\+Intercept=false)
\begin{DoxyCompactList}\small\item\em Initialize Linear S\+VM weights (trainable parameters) with the given parameters. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Mat\+Type = arma\+::mat$>$\newline
class mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$}

The hinge loss function for the linear S\+VM objective function. 

This is used by various ensmallen optimizers to train the linear S\+VM model. 

Definition at line 28 of file linear\+\_\+svm\+\_\+function.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_af445da901fbdbaf4a6624eb7c59a219f}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Linear\+S\+V\+M\+Function@{Linear\+S\+V\+M\+Function}}
\index{Linear\+S\+V\+M\+Function@{Linear\+S\+V\+M\+Function}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Linear\+S\+V\+M\+Function()}
{\footnotesize\ttfamily \textbf{ Linear\+S\+V\+M\+Function} (\begin{DoxyParamCaption}\item[{const Mat\+Type \&}]{dataset,  }\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels,  }\item[{const size\+\_\+t}]{num\+Classes,  }\item[{const double}]{lambda = {\ttfamily 0.0001},  }\item[{const double}]{delta = {\ttfamily 1.0},  }\item[{const bool}]{fit\+Intercept = {\ttfamily false} }\end{DoxyParamCaption})}



Construct the Linear S\+VM objective function with given parameters. 


\begin{DoxyParams}{Parameters}
{\em dataset} & Input training data, each column associate with one sample \\
\hline
{\em labels} & Labels associated with the feature data. \\
\hline
{\em num\+Classes} & Number of classes for classification. \\
\hline
{\em lambda} & L2-\/regularization constant. \\
\hline
{\em delta} & Margin of difference between correct class and other classes. \\
\hline
{\em fit\+Intercept} & Intercept term flag. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a63f50b704711fa3661dc1ae565f51811}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Dataset@{Dataset}}
\index{Dataset@{Dataset}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Dataset()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const arma\+::sp\+\_\+mat\& Dataset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the dataset. 



Definition at line 166 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_ae7b442671b21a94780f17a6624e1f31d}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Dataset@{Dataset}}
\index{Dataset@{Dataset}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Dataset()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily arma\+::sp\+\_\+mat\& Dataset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the dataset. 



Definition at line 168 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a1ca0efaedbc2e7e7542c89901cdcf2ee}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Evaluate@{Evaluate}}
\index{Evaluate@{Evaluate}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Evaluate()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Evaluate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters }\end{DoxyParamCaption})}



Evaluate the hinge loss function for all the datapoints. 


\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The value of the loss function for the entire dataset. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a3b3e9347c2b7e25c47f3fba3baf12d19}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Evaluate@{Evaluate}}
\index{Evaluate@{Evaluate}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Evaluate()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Evaluate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters,  }\item[{const size\+\_\+t}]{first\+Id,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption})}



Evaluate the hinge loss function on the specified datapoints. 


\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
{\em first\+Id} & Index of the datapoints to use for function evaluation. \\
\hline
{\em batch\+Size} & Size of batch to process. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The value of the loss function for the given parameters. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a1e5f0be6eadfa83bbea6f6152d04f735}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}}
\index{Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Evaluate\+With\+Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Evaluate\+With\+Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters,  }\item[{Grad\+Type \&}]{gradient }\end{DoxyParamCaption}) const}



Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function followed by evaluation of the hinge loss function on all the datapoints. 


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & Type of the gradient matrix. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
{\em gradient} & Linear matrix to output the gradient into. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The value of the loss function at the given parameters. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a116bf353d6114dbaddc9bcad60f690b1}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}}
\index{Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Evaluate\+With\+Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Evaluate\+With\+Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters,  }\item[{const size\+\_\+t}]{first\+Id,  }\item[{Grad\+Type \&}]{gradient,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption}) const}



Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function followed by evaluation of the hinge loss function on the specified datapoints. 


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & Type of the gradient matrix. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
{\em first\+Id} & Index of the datapoint to use for the gradient and function evaluation. \\
\hline
{\em gradient} & Linear matrix to output the gradient into. \\
\hline
{\em batch\+Size} & Size of the batch to process. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The value of the loss function at the given parameters. 
\end{DoxyReturn}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a2878e0828ecdc1d486b0f43a81f95059}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Fit\+Intercept@{Fit\+Intercept}}
\index{Fit\+Intercept@{Fit\+Intercept}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Fit\+Intercept()}
{\footnotesize\ttfamily bool Fit\+Intercept (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Gets the intercept flag. 



Definition at line 176 of file linear\+\_\+svm\+\_\+function.\+hpp.



References Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$\+::\+Num\+Functions().

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_afb090fbee5f880dd69edde4cdd0797cd}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Get\+Ground\+Truth\+Matrix@{Get\+Ground\+Truth\+Matrix}}
\index{Get\+Ground\+Truth\+Matrix@{Get\+Ground\+Truth\+Matrix}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Get\+Ground\+Truth\+Matrix()}
{\footnotesize\ttfamily void Get\+Ground\+Truth\+Matrix (\begin{DoxyParamCaption}\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels,  }\item[{arma\+::sp\+\_\+mat \&}]{ground\+Truth }\end{DoxyParamCaption})}



Constructs the ground truth label matrix with the passed labels. 


\begin{DoxyParams}{Parameters}
{\em labels} & Labels associated with the training data. \\
\hline
{\em ground\+Truth} & Pointer to arma\+::mat which stores the computed matrix. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a306147f4dffda5b0972a12de487ece8e}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters,  }\item[{Grad\+Type \&}]{gradient }\end{DoxyParamCaption})}



Evaluate the gradient of the hinge loss function following the Linear\+Function\+Type requirements on the Gradient function. 


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & Type of the gradient matrix. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
{\em gradient} & Linear matrix to output the gradient into. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_ac193621da3a050a935bacdc988b990b8}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{parameters,  }\item[{const size\+\_\+t}]{first\+Id,  }\item[{Grad\+Type \&}]{gradient,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption})}



Evaluate the gradient of the hinge loss function, following the Linear\+Function\+Type requirements on the Gradient function. 


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & Type of the gradient matrix. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em parameters} & The parameters of the S\+VM. \\
\hline
{\em first\+Id} & Index of the datapoint to use for the gradient evaluation. \\
\hline
{\em gradient} & Linear matrix to output the gradient into. \\
\hline
{\em batch\+Size} & Size of the batch to process. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_af39490b2ae62f54b6a4c25a3d92ab0ce}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Initialize\+Weights@{Initialize\+Weights}}
\index{Initialize\+Weights@{Initialize\+Weights}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Initialize\+Weights()}
{\footnotesize\ttfamily static void Initialize\+Weights (\begin{DoxyParamCaption}\item[{arma\+::mat \&}]{weights,  }\item[{const size\+\_\+t}]{feature\+Size,  }\item[{const size\+\_\+t}]{num\+Classes,  }\item[{const bool}]{fit\+Intercept = {\ttfamily false} }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Initialize Linear S\+VM weights (trainable parameters) with the given parameters. 


\begin{DoxyParams}{Parameters}
{\em weights} & This will be filled with the initialized model weights. \\
\hline
{\em feature\+Size} & The number of features in the training set. \\
\hline
{\em num\+Classes} & Number of classes for classification. \\
\hline
{\em fit\+Intercept} & If true, an intercept is fitted. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a380e98a13444e16f7cd2984e23b32e2e}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Initial\+Point@{Initial\+Point}}
\index{Initial\+Point@{Initial\+Point}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Initial\+Point()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const arma\+::mat\& Initial\+Point (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return the initial point for the optimization. 



Definition at line 161 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_ab1582fd207a6b9a400cf27c710c5af06}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Initial\+Point@{Initial\+Point}}
\index{Initial\+Point@{Initial\+Point}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Initial\+Point()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily arma\+::mat\& Initial\+Point (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the initial point for the optimization. 



Definition at line 163 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_aaf66629b989a326453647f42443c6a0c}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Lambda()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double\& Lambda (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Sets the regularization parameter. 



Definition at line 171 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a53535041275cedd0ec3de67ca032aa94}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Lambda@{Lambda}}
\index{Lambda@{Lambda}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Lambda()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Lambda (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Gets the regularization parameter. 



Definition at line 173 of file linear\+\_\+svm\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a1fa76af34a6e3ea927b307f0c318ee4b}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Num\+Functions@{Num\+Functions}}
\index{Num\+Functions@{Num\+Functions}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Num\+Functions()}
{\footnotesize\ttfamily size\+\_\+t Num\+Functions (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const}



Return the number of functions. 



Referenced by Linear\+S\+V\+M\+Function$<$ Mat\+Type $>$\+::\+Fit\+Intercept().

\mbox{\label{classmlpack_1_1svm_1_1LinearSVMFunction_a2697cc8b37d7bca7c055228382a9b208}} 
\index{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}!Shuffle@{Shuffle}}
\index{Shuffle@{Shuffle}!mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function@{mlpack\+::svm\+::\+Linear\+S\+V\+M\+Function}}
\subsubsection{Shuffle()}
{\footnotesize\ttfamily void Shuffle (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Shuffle the dataset. 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/linear\+\_\+svm/\textbf{ linear\+\_\+svm\+\_\+function.\+hpp}\end{DoxyCompactItemize}
