\section{Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$ Class Template Reference}
\label{classmlpack_1_1ann_1_1AddMerge}\index{Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$@{Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$}}


Implementation of the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} module class.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Add\+Merge} (const bool model=false, const bool run=true)
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} object using the specified parameters. \end{DoxyCompactList}\item 
\textbf{ Add\+Merge} (const bool model, const bool run, const bool owns\+Layers)
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} object using the specified parameters. \end{DoxyCompactList}\item 
\textbf{ $\sim$\+Add\+Merge} ()
\begin{DoxyCompactList}\small\item\em Destructor to release allocated memory. \end{DoxyCompactList}\item 
{\footnotesize template$<$class Layer\+Type , class... Args$>$ }\\void \textbf{ Add} (Args... args)
\item 
void \textbf{ Add} (\textbf{ Layer\+Types}$<$ Custom\+Layers... $>$ layer)
\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Backward} (const arma\+::\+Mat$<$ eT $>$ \&, const arma\+::\+Mat$<$ eT $>$ \&gy, arma\+::\+Mat$<$ eT $>$ \&g)
\begin{DoxyCompactList}\small\item\em Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Backward} (const arma\+::\+Mat$<$ eT $>$ \&, const arma\+::\+Mat$<$ eT $>$ \&gy, arma\+::\+Mat$<$ eT $>$ \&g, const size\+\_\+t index)
\begin{DoxyCompactList}\small\item\em This is the overload of \doxyref{Backward()}{p.}{classmlpack_1_1ann_1_1AddMerge_ad9ad1a3bdb0f3fff5c839ed155e4bbf8} that runs only a specific layer with the given input. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Delta} () const
\begin{DoxyCompactList}\small\item\em Get the delta. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Delta} ()
\begin{DoxyCompactList}\small\item\em Modify the delta. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Input\+Type , typename Output\+Type $>$ }\\void \textbf{ Forward} (const Input\+Type \&, Output\+Type \&output)
\begin{DoxyCompactList}\small\item\em Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Gradient} (const arma\+::\+Mat$<$ eT $>$ \&input, const arma\+::\+Mat$<$ eT $>$ \&error, arma\+::\+Mat$<$ eT $>$ \&gradient)
\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Gradient} (const arma\+::\+Mat$<$ eT $>$ \&input, const arma\+::\+Mat$<$ eT $>$ \&error, arma\+::\+Mat$<$ eT $>$ \&gradient, const size\+\_\+t index)
\item 
Input\+Data\+Type const  \& \textbf{ Input\+Parameter} () const
\begin{DoxyCompactList}\small\item\em Get the input parameter. \end{DoxyCompactList}\item 
Input\+Data\+Type \& \textbf{ Input\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the input parameter. \end{DoxyCompactList}\item 
std\+::vector$<$ \textbf{ Layer\+Types}$<$ Custom\+Layers... $>$ $>$ \& \textbf{ Model} ()
\begin{DoxyCompactList}\small\item\em Return the model modules. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Output\+Parameter} () const
\begin{DoxyCompactList}\small\item\em Get the output parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Output\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the output parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Parameters} () const
\begin{DoxyCompactList}\small\item\em Get the parameters. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Parameters} ()
\begin{DoxyCompactList}\small\item\em Modify the parameters. \end{DoxyCompactList}\item 
bool \textbf{ Run} () const
\begin{DoxyCompactList}\small\item\em Get the value of run parameter. \end{DoxyCompactList}\item 
bool \& \textbf{ Run} ()
\begin{DoxyCompactList}\small\item\em Modify the value of run parameter. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Archive $>$ }\\void \textbf{ serialize} (Archive \&ar, const uint32\+\_\+t)
\begin{DoxyCompactList}\small\item\em Serialize the layer. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Input\+Data\+Type = arma\+::mat, typename Output\+Data\+Type = arma\+::mat, typename... Custom\+Layers$>$\newline
class mlpack\+::ann\+::\+Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$}

Implementation of the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} module class. 

The \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} class accumulates the output of various modules.


\begin{DoxyTemplParams}{Template Parameters}
{\em Input\+Data\+Type} & Type of the input data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
{\em Output\+Data\+Type} & Type of the output data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
{\em Custom\+Layers} & Additional custom layers that can be added. \\
\hline
\end{DoxyTemplParams}


Definition at line 42 of file add\+\_\+merge.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_aa3a9322cccc5043ba480a7b9f8ca055a}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Add\+Merge@{Add\+Merge}}
\index{Add\+Merge@{Add\+Merge}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Add\+Merge()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \textbf{ Add\+Merge} (\begin{DoxyParamCaption}\item[{const bool}]{model = {\ttfamily false},  }\item[{const bool}]{run = {\ttfamily true} }\end{DoxyParamCaption})}



Create the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} object using the specified parameters. 


\begin{DoxyParams}{Parameters}
{\em model} & Expose all the network modules. \\
\hline
{\em run} & Call the Forward/\+Backward method before the output is merged. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a5679dd6a65935fa79b54de8be0818ca6}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Add\+Merge@{Add\+Merge}}
\index{Add\+Merge@{Add\+Merge}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Add\+Merge()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \textbf{ Add\+Merge} (\begin{DoxyParamCaption}\item[{const bool}]{model,  }\item[{const bool}]{run,  }\item[{const bool}]{owns\+Layers }\end{DoxyParamCaption})}



Create the \doxyref{Add\+Merge}{p.}{classmlpack_1_1ann_1_1AddMerge} object using the specified parameters. 


\begin{DoxyParams}{Parameters}
{\em model} & Expose all the network modules. \\
\hline
{\em run} & Call the Forward/\+Backward method before the output is merged. \\
\hline
{\em owns\+Layers} & Delete the layers when this is deallocated. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_addb097051de29df7c561e1fa8144b4f7}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!````~Add\+Merge@{$\sim$\+Add\+Merge}}
\index{````~Add\+Merge@{$\sim$\+Add\+Merge}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{$\sim$\+Add\+Merge()}
{\footnotesize\ttfamily $\sim$\textbf{ Add\+Merge} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Destructor to release allocated memory. 



\subsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a8b5234495846c00f6b2c8296ca6bc718}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Add@{Add}}
\index{Add@{Add}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Add()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void \textbf{ Add} (\begin{DoxyParamCaption}\item[{Args...}]{args }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Definition at line 137 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a503a807740e6c729be9efc89520db728}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Add@{Add}}
\index{Add@{Add}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Add()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void \textbf{ Add} (\begin{DoxyParamCaption}\item[{\textbf{ Layer\+Types}$<$ Custom\+Layers... $>$}]{layer }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Definition at line 144 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_ad9ad1a3bdb0f3fff5c839ed155e4bbf8}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Backward@{Backward}}
\index{Backward@{Backward}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Backward()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void Backward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{gy,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{g }\end{DoxyParamCaption})}



Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. 

Using the results from the feed forward pass.


\begin{DoxyParams}{Parameters}
{\em $\ast$} & (input) The propagated input activation. \\
\hline
{\em gy} & The backpropagated error. \\
\hline
{\em g} & The calculated gradient. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a32bcd789dbfae1bd33009208d783af03}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Backward@{Backward}}
\index{Backward@{Backward}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Backward()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void Backward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{gy,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{g,  }\item[{const size\+\_\+t}]{index }\end{DoxyParamCaption})}



This is the overload of \doxyref{Backward()}{p.}{classmlpack_1_1ann_1_1AddMerge_ad9ad1a3bdb0f3fff5c839ed155e4bbf8} that runs only a specific layer with the given input. 


\begin{DoxyParams}{Parameters}
{\em $\ast$} & (input) The propagated input activation. \\
\hline
{\em gy} & The backpropagated error. \\
\hline
{\em g} & The calculated gradient. \\
\hline
{\em index} & The index of the layer to run. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a797f7edb44dd081e5e2b3cc316eef6bd}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the delta. 



Definition at line 157 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_ad6601342d560219ce951d554e69e5e87}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the delta. 



Definition at line 159 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a15104aebf957ca49a0e3828abda5417f}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Forward@{Forward}}
\index{Forward@{Forward}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Forward()}
{\footnotesize\ttfamily void Forward (\begin{DoxyParamCaption}\item[{const Input\+Type \&}]{,  }\item[{Output\+Type \&}]{output }\end{DoxyParamCaption})}



Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. 


\begin{DoxyParams}{Parameters}
{\em $\ast$} & (input) Input data used for evaluating the specified function. \\
\hline
{\em output} & Resulting output activation. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1AddMerge_aaf577db350e2130754490d8486fba215}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{error,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{gradient }\end{DoxyParamCaption})}

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a3a788180c1f383a92cc99dd6d7d86bfc}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{error,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{gradient,  }\item[{const size\+\_\+t}]{index }\end{DoxyParamCaption})}

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_aaffd593b3ab627f8b5aae2a1f53634b0}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Input\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Input\+Data\+Type const\& Input\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the input parameter. 



Definition at line 147 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a063c3b1053c7979a7dd2e7bbd2bf1f8a}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Input\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Input\+Data\+Type\& Input\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the input parameter. 



Definition at line 149 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a4cb1e93bff99ccf1f8f974065a3b13c3}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Model@{Model}}
\index{Model@{Model}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Model()}
{\footnotesize\ttfamily std\+::vector$<$\textbf{ Layer\+Types}$<$Custom\+Layers...$>$ $>$\& Model (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Return the model modules. 



Definition at line 162 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a0ee21c2a36e5abad1e7a9d5dd00849f9}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Output\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the output parameter. 



Definition at line 152 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a21d5f745f02c709625a4ee0907f004a5}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Output\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the output parameter. 



Definition at line 154 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_aa530552c7ef915c952fbacc77b965c90}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the parameters. 



Definition at line 173 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a9c5c5900772a689d5a6b59778ec67120}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the parameters. 



Definition at line 175 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_afdada2aebea2e6674e47bde6f697b0b8}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Run@{Run}}
\index{Run@{Run}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Run()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily bool Run (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the value of run parameter. 



Definition at line 178 of file add\+\_\+merge.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a6d2eb043777b8a5e63ff8746b3cf980c}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!Run@{Run}}
\index{Run@{Run}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{Run()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily bool\& Run (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the value of run parameter. 



Definition at line 180 of file add\+\_\+merge.\+hpp.



References Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$\+::serialize().

\mbox{\label{classmlpack_1_1ann_1_1AddMerge_a65cba07328997659bec80b9879b15a51}} 
\index{mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}!serialize@{serialize}}
\index{serialize@{serialize}!mlpack\+::ann\+::\+Add\+Merge@{mlpack\+::ann\+::\+Add\+Merge}}
\subsubsection{serialize()}
{\footnotesize\ttfamily void serialize (\begin{DoxyParamCaption}\item[{Archive \&}]{ar,  }\item[{const uint32\+\_\+t}]{ }\end{DoxyParamCaption})}



Serialize the layer. 



Referenced by Add\+Merge$<$ Input\+Data\+Type, Output\+Data\+Type, Custom\+Layers $>$\+::\+Run().



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/ann/layer/\textbf{ add\+\_\+merge.\+hpp}\end{DoxyCompactItemize}
