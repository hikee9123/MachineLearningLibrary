\section{L\+M\+N\+N\+Function$<$ Metric\+Type $>$ Class Template Reference}
\label{classmlpack_1_1lmnn_1_1LMNNFunction}\index{L\+M\+N\+N\+Function$<$ Metric\+Type $>$@{L\+M\+N\+N\+Function$<$ Metric\+Type $>$}}


The Large Margin Nearest Neighbors function.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ L\+M\+N\+N\+Function} (const arma\+::mat \&dataset, const arma\+::\+Row$<$ size\+\_\+t $>$ \&labels, size\+\_\+t k, double regularization, size\+\_\+t range, Metric\+Type metric=Metric\+Type())
\begin{DoxyCompactList}\small\item\em Constructor for \doxyref{L\+M\+N\+N\+Function}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction} class. \end{DoxyCompactList}\item 
const arma\+::mat \& \textbf{ Dataset} () const
\begin{DoxyCompactList}\small\item\em Return the dataset passed into the constructor. \end{DoxyCompactList}\item 
double \textbf{ Evaluate} (const arma\+::mat \&transformation)
\begin{DoxyCompactList}\small\item\em Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix. \end{DoxyCompactList}\item 
double \textbf{ Evaluate} (const arma\+::mat \&transformation, const size\+\_\+t begin, const size\+\_\+t batch\+Size=1)
\begin{DoxyCompactList}\small\item\em Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function for the given transformation matrix on the given batch size from a given inital point of the dataset. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\double \textbf{ Evaluate\+With\+Gradient} (const arma\+::mat \&transformation, Grad\+Type \&gradient)
\begin{DoxyCompactList}\small\item\em Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function together with gradient for the given transformation matrix. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\double \textbf{ Evaluate\+With\+Gradient} (const arma\+::mat \&transformation, const size\+\_\+t begin, Grad\+Type \&gradient, const size\+\_\+t batch\+Size=1)
\begin{DoxyCompactList}\small\item\em Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function together with gradient for the given transformation matrix on the given batch size, from a given initial point of the dataset. \end{DoxyCompactList}\item 
const arma\+::mat \& \textbf{ Get\+Initial\+Point} () const
\begin{DoxyCompactList}\small\item\em Return the initial point for the optimization. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\void \textbf{ Gradient} (const arma\+::mat \&transformation, Grad\+Type \&gradient)
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename Grad\+Type $>$ }\\void \textbf{ Gradient} (const arma\+::mat \&transformation, const size\+\_\+t begin, Grad\+Type \&gradient, const size\+\_\+t batch\+Size=1)
\begin{DoxyCompactList}\small\item\em Evaluate the gradient of the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix on the given batch size, from a given initial point of the dataset. \end{DoxyCompactList}\item 
const size\+\_\+t \& \textbf{ K} () const
\begin{DoxyCompactList}\small\item\em Access the value of k. \end{DoxyCompactList}\item 
size\+\_\+t \& \textbf{ K} ()
\begin{DoxyCompactList}\small\item\em Modify the value of k. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Num\+Functions} () const
\begin{DoxyCompactList}\small\item\em Get the number of functions the objective function can be decomposed into. \end{DoxyCompactList}\item 
const size\+\_\+t \& \textbf{ Range} () const
\begin{DoxyCompactList}\small\item\em Access the value of range. \end{DoxyCompactList}\item 
size\+\_\+t \& \textbf{ Range} ()
\begin{DoxyCompactList}\small\item\em Modify the value of k. \end{DoxyCompactList}\item 
const double \& \textbf{ Regularization} () const
\begin{DoxyCompactList}\small\item\em Access the regularization value. \end{DoxyCompactList}\item 
double \& \textbf{ Regularization} ()
\begin{DoxyCompactList}\small\item\em Modify the regularization value. \end{DoxyCompactList}\item 
void \textbf{ Shuffle} ()
\begin{DoxyCompactList}\small\item\em Shuffle the points in the dataset. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Metric\+Type = metric\+::\+Squared\+Euclidean\+Distance$>$\newline
class mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function$<$ Metric\+Type $>$}

The Large Margin Nearest Neighbors function. 

The actual function is

$ \epsilon(M) = \sum_{ij}\eta_{ij}|| L x_i - L x_j ||^2 + c\sum_{ijl}\eta_{ij}(1-y_{il})[1 + || L x_i - L x_j ||^2 - || L x_i - L x_l ||^2)]_{+} $

where x\+\_\+n represents a point and A is the current scaling matrix.

This class is more flexible than the original paper, allowing an arbitrary metric function to be used in place of $\vert$$\vert$ A x\+\_\+i -\/ A x\+\_\+j $\vert$$\vert$$^\wedge$2, meaning that the squared Euclidean distance is not the only allowed metric for \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN}. However, that is probably the best way to use this class.

In addition to the standard \doxyref{Evaluate()}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction_a984a5518a600950a14782757aea93b59} and \doxyref{Gradient()}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction_a8ab4bb24874b8bd6fee743b169f1d059} functions which mlpack optimizers use, overloads of \doxyref{Evaluate()}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction_a984a5518a600950a14782757aea93b59} and \doxyref{Gradient()}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction_a8ab4bb24874b8bd6fee743b169f1d059} are given which only operate on one point in the dataset. This is useful for optimizers like stochastic gradient descent (see ens\+::\+S\+GD). 

Definition at line 46 of file lmnn\+\_\+function.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ad5d0ec2e3f5998fce48a99a212437c7b}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!L\+M\+N\+N\+Function@{L\+M\+N\+N\+Function}}
\index{L\+M\+N\+N\+Function@{L\+M\+N\+N\+Function}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{L\+M\+N\+N\+Function()}
{\footnotesize\ttfamily \textbf{ L\+M\+N\+N\+Function} (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{dataset,  }\item[{const arma\+::\+Row$<$ size\+\_\+t $>$ \&}]{labels,  }\item[{size\+\_\+t}]{k,  }\item[{double}]{regularization,  }\item[{size\+\_\+t}]{range,  }\item[{Metric\+Type}]{metric = {\ttfamily MetricType()} }\end{DoxyParamCaption})}



Constructor for \doxyref{L\+M\+N\+N\+Function}{p.}{classmlpack_1_1lmnn_1_1LMNNFunction} class. 


\begin{DoxyParams}{Parameters}
{\em dataset} & Input dataset. \\
\hline
{\em labels} & Input dataset labels. \\
\hline
{\em k} & Number of target neighbors to be used. \\
\hline
{\em regularization} & Regularization value. \\
\hline
{\em range} & Range after which impostors need to be recalculated. \\
\hline
{\em metric} & Type of metric used for computation. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_aff320b9a86b77a150e630c01d5888273}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Dataset@{Dataset}}
\index{Dataset@{Dataset}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Dataset()}
{\footnotesize\ttfamily const arma\+::mat\& Dataset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return the dataset passed into the constructor. 



Definition at line 175 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a984a5518a600950a14782757aea93b59}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Evaluate@{Evaluate}}
\index{Evaluate@{Evaluate}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Evaluate()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Evaluate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation }\end{DoxyParamCaption})}



Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix. 

This is the non-\/separable implementation, where the objective function is not decomposed into the sum of several objective functions.


\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a3ec40724bffda10e022fdaf072fae3ac}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Evaluate@{Evaluate}}
\index{Evaluate@{Evaluate}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Evaluate()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Evaluate (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation,  }\item[{const size\+\_\+t}]{begin,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption})}



Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function for the given transformation matrix on the given batch size from a given inital point of the dataset. 

This is the separable implementation, where the objective function is decomposed into the sum of many objective functions, and here, only one of those constituent objective functions is returned.


\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
{\em begin} & Index of the initial point to use for objective function. \\
\hline
{\em batch\+Size} & Number of points to use for objective function. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a18208d5789919b6d12eaaffe007b7dcf}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}}
\index{Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Evaluate\+With\+Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Evaluate\+With\+Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation,  }\item[{Grad\+Type \&}]{gradient }\end{DoxyParamCaption})}



Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function together with gradient for the given transformation matrix. 

This is the non-\/separable implementation, where the objective function is not decomposed into the sum of several objective functions.


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & The type of the gradient out-\/param. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
{\em gradient} & Matrix to store the calculated gradient in. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a71970d9b9013a39efd08c1054c077557}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}}
\index{Evaluate\+With\+Gradient@{Evaluate\+With\+Gradient}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Evaluate\+With\+Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double Evaluate\+With\+Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation,  }\item[{const size\+\_\+t}]{begin,  }\item[{Grad\+Type \&}]{gradient,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption})}



Evaluate the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} objective function together with gradient for the given transformation matrix on the given batch size, from a given initial point of the dataset. 

This is the separable implementation, where the objective function is decomposed into the sum of many objective functions, and here, only one of those constituent objective functions is returned. The type of the gradient parameter is a template argument to allow the computation of a sparse gradient.


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & The type of the gradient out-\/param. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
{\em begin} & Index of the initial point to use for objective function. \\
\hline
{\em gradient} & Matrix to store the calculated gradient in. \\
\hline
{\em batch\+Size} & Number of points to use for objective function. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ac3e9aa612cb56d0d93f3259f4a8122bb}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Get\+Initial\+Point@{Get\+Initial\+Point}}
\index{Get\+Initial\+Point@{Get\+Initial\+Point}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Get\+Initial\+Point()}
{\footnotesize\ttfamily const arma\+::mat\& Get\+Initial\+Point (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Return the initial point for the optimization. 



Definition at line 166 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a8ab4bb24874b8bd6fee743b169f1d059}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation,  }\item[{Grad\+Type \&}]{gradient }\end{DoxyParamCaption})}



Evaluate the gradient of the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix. 

This is the non-\/separable implementation, where the objective function is not decomposed into the sum of several objective functions.


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & The type of the gradient out-\/param. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
{\em gradient} & Matrix to store the calculated gradient in. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ac15fcb34b662aa35bb6fb4a089ae1de4}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{transformation,  }\item[{const size\+\_\+t}]{begin,  }\item[{Grad\+Type \&}]{gradient,  }\item[{const size\+\_\+t}]{batch\+Size = {\ttfamily 1} }\end{DoxyParamCaption})}



Evaluate the gradient of the \doxyref{L\+M\+NN}{p.}{classmlpack_1_1lmnn_1_1LMNN} function for the given transformation matrix on the given batch size, from a given initial point of the dataset. 

This is the separable implementation, where the objective function is decomposed into the sum of many objective functions, and here, only one of those constituent objective functions is returned. The type of the gradient parameter is a template argument to allow the computation of a sparse gradient.


\begin{DoxyTemplParams}{Template Parameters}
{\em Grad\+Type} & The type of the gradient out-\/param. \\
\hline
\end{DoxyTemplParams}

\begin{DoxyParams}{Parameters}
{\em transformation} & Transformation matrix of Mahalanobis distance. \\
\hline
{\em begin} & Index of the initial point to use for objective function. \\
\hline
{\em gradient} & Matrix to store the calculated gradient in. \\
\hline
{\em batch\+Size} & Number of points to use for objective function. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ab749ea30c4c3d750ef3a619f32dc3e75}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!K@{K}}
\index{K@{K}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{K()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const size\+\_\+t\& K (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Access the value of k. 



Definition at line 183 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_af80ea69c69c6463691509f509f3bff05}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!K@{K}}
\index{K@{K}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{K()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily size\+\_\+t\& K (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the value of k. 



Definition at line 185 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a1fa76af34a6e3ea927b307f0c318ee4b}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Num\+Functions@{Num\+Functions}}
\index{Num\+Functions@{Num\+Functions}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Num\+Functions()}
{\footnotesize\ttfamily size\+\_\+t Num\+Functions (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the number of functions the objective function can be decomposed into. 

This is just the number of points in the dataset. 

Definition at line 172 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a8a26c8724520d749b483fe8dcfe7416b}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Range@{Range}}
\index{Range@{Range}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Range()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const size\+\_\+t\& Range (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Access the value of range. 



Definition at line 188 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ab2cebd1b43cb779465e7323255112bb4}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Range@{Range}}
\index{Range@{Range}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Range()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily size\+\_\+t\& Range (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the value of k. 



Definition at line 190 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_ad3a3c8f810d08e2e922b3c30e29b7f11}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Regularization@{Regularization}}
\index{Regularization@{Regularization}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Regularization()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily const double\& Regularization (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Access the regularization value. 



Definition at line 178 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a9c741ac26a2c0ee8bb0fbe52534dd544}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Regularization@{Regularization}}
\index{Regularization@{Regularization}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Regularization()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily double\& Regularization (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the regularization value. 



Definition at line 180 of file lmnn\+\_\+function.\+hpp.

\mbox{\label{classmlpack_1_1lmnn_1_1LMNNFunction_a2697cc8b37d7bca7c055228382a9b208}} 
\index{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}!Shuffle@{Shuffle}}
\index{Shuffle@{Shuffle}!mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function@{mlpack\+::lmnn\+::\+L\+M\+N\+N\+Function}}
\subsubsection{Shuffle()}
{\footnotesize\ttfamily void Shuffle (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Shuffle the points in the dataset. 

This may be used by optimizers. 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/lmnn/\textbf{ lmnn\+\_\+function.\+hpp}\end{DoxyCompactItemize}
