\section{Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$ Class Template Reference}
\label{classmlpack_1_1ann_1_1Linear}\index{Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$@{Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$}}


Implementation of the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer class.  


\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Linear} ()
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} object. \end{DoxyCompactList}\item 
\textbf{ Linear} (const size\+\_\+t in\+Size, const size\+\_\+t out\+Size, Regularizer\+Type regularizer=Regularizer\+Type())
\begin{DoxyCompactList}\small\item\em Create the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer object using the specified number of units. \end{DoxyCompactList}\item 
\textbf{ Linear} (const \textbf{ Linear} \&layer)
\begin{DoxyCompactList}\small\item\em Copy constructor. \end{DoxyCompactList}\item 
\textbf{ Linear} (\textbf{ Linear} \&\&)
\begin{DoxyCompactList}\small\item\em Move constructor. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Backward} (const arma\+::\+Mat$<$ eT $>$ \&, const arma\+::\+Mat$<$ eT $>$ \&gy, arma\+::\+Mat$<$ eT $>$ \&g)
\begin{DoxyCompactList}\small\item\em Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Bias} () const
\begin{DoxyCompactList}\small\item\em Get the bias of the layer. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Bias} ()
\begin{DoxyCompactList}\small\item\em Modify the bias weights of the layer. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Delta} () const
\begin{DoxyCompactList}\small\item\em Get the delta. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Delta} ()
\begin{DoxyCompactList}\small\item\em Modify the delta. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Forward} (const arma\+::\+Mat$<$ eT $>$ \&input, arma\+::\+Mat$<$ eT $>$ \&output)
\begin{DoxyCompactList}\small\item\em Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. \end{DoxyCompactList}\item 
{\footnotesize template$<$typename eT $>$ }\\void \textbf{ Gradient} (const arma\+::\+Mat$<$ eT $>$ \&input, const arma\+::\+Mat$<$ eT $>$ \&error, arma\+::\+Mat$<$ eT $>$ \&gradient)
\item 
Output\+Data\+Type const  \& \textbf{ Gradient} () const
\begin{DoxyCompactList}\small\item\em Get the gradient. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Gradient} ()
\begin{DoxyCompactList}\small\item\em Modify the gradient. \end{DoxyCompactList}\item 
Input\+Data\+Type const  \& \textbf{ Input\+Parameter} () const
\begin{DoxyCompactList}\small\item\em Get the input parameter. \end{DoxyCompactList}\item 
Input\+Data\+Type \& \textbf{ Input\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the input parameter. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Input\+Shape} () const
\begin{DoxyCompactList}\small\item\em Get the shape of the input. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Input\+Size} () const
\begin{DoxyCompactList}\small\item\em Get the input size. \end{DoxyCompactList}\item 
\textbf{ Linear} \& \textbf{ operator=} (const \textbf{ Linear} \&layer)
\begin{DoxyCompactList}\small\item\em Copy assignment operator. \end{DoxyCompactList}\item 
\textbf{ Linear} \& \textbf{ operator=} (\textbf{ Linear} \&\&layer)
\begin{DoxyCompactList}\small\item\em Move assignment operator. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Output\+Parameter} () const
\begin{DoxyCompactList}\small\item\em Get the output parameter. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Output\+Parameter} ()
\begin{DoxyCompactList}\small\item\em Modify the output parameter. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Output\+Size} () const
\begin{DoxyCompactList}\small\item\em Get the output size. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Parameters} () const
\begin{DoxyCompactList}\small\item\em Get the parameters. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Parameters} ()
\begin{DoxyCompactList}\small\item\em Modify the parameters. \end{DoxyCompactList}\item 
void \textbf{ Reset} ()
\item 
{\footnotesize template$<$typename Archive $>$ }\\void \textbf{ serialize} (Archive \&ar, const uint32\+\_\+t)
\begin{DoxyCompactList}\small\item\em Serialize the layer. \end{DoxyCompactList}\item 
Output\+Data\+Type const  \& \textbf{ Weight} () const
\begin{DoxyCompactList}\small\item\em Get the weight of the layer. \end{DoxyCompactList}\item 
Output\+Data\+Type \& \textbf{ Weight} ()
\begin{DoxyCompactList}\small\item\em Modify the weight of the layer. \end{DoxyCompactList}\item 
size\+\_\+t \textbf{ Weight\+Size} () const
\begin{DoxyCompactList}\small\item\em Get the size of the weights. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Input\+Data\+Type = arma\+::mat, typename Output\+Data\+Type = arma\+::mat, typename Regularizer\+Type = No\+Regularizer$>$\newline
class mlpack\+::ann\+::\+Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$}

Implementation of the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer class. 

The \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} class represents a single layer of a neural network.


\begin{DoxyTemplParams}{Template Parameters}
{\em Input\+Data\+Type} & Type of the input data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
{\em Output\+Data\+Type} & Type of the output data (arma\+::colvec, arma\+::mat, arma\+::sp\+\_\+mat or arma\+::cube). \\
\hline
\end{DoxyTemplParams}


Definition at line 89 of file layer\+\_\+types.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1ann_1_1Linear_a74718d0ddfb023a44f6178db18c6bd4a}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Linear@{Linear}}
\index{Linear@{Linear}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Linear()\hspace{0.1cm}{\footnotesize\ttfamily [1/4]}}
{\footnotesize\ttfamily \textbf{ Linear} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Create the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} object. 

\mbox{\label{classmlpack_1_1ann_1_1Linear_a1c63b8043ac43d2f9d1187a4b806b36b}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Linear@{Linear}}
\index{Linear@{Linear}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Linear()\hspace{0.1cm}{\footnotesize\ttfamily [2/4]}}
{\footnotesize\ttfamily \textbf{ Linear} (\begin{DoxyParamCaption}\item[{const size\+\_\+t}]{in\+Size,  }\item[{const size\+\_\+t}]{out\+Size,  }\item[{Regularizer\+Type}]{regularizer = {\ttfamily RegularizerType()} }\end{DoxyParamCaption})}



Create the \doxyref{Linear}{p.}{classmlpack_1_1ann_1_1Linear} layer object using the specified number of units. 


\begin{DoxyParams}{Parameters}
{\em in\+Size} & The number of input units. \\
\hline
{\em out\+Size} & The number of output units. \\
\hline
{\em regularizer} & The regularizer to use, optional. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Linear_a05deb958a4608987299a4d5c0e3aa3bb}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Linear@{Linear}}
\index{Linear@{Linear}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Linear()\hspace{0.1cm}{\footnotesize\ttfamily [3/4]}}
{\footnotesize\ttfamily \textbf{ Linear} (\begin{DoxyParamCaption}\item[{const \textbf{ Linear}$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$ \&}]{layer }\end{DoxyParamCaption})}



Copy constructor. 

\mbox{\label{classmlpack_1_1ann_1_1Linear_a40b7f2081aac98347cf48c467dba2829}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Linear@{Linear}}
\index{Linear@{Linear}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Linear()\hspace{0.1cm}{\footnotesize\ttfamily [4/4]}}
{\footnotesize\ttfamily \textbf{ Linear} (\begin{DoxyParamCaption}\item[{\textbf{ Linear}$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$ \&\&}]{ }\end{DoxyParamCaption})}



Move constructor. 



\subsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1ann_1_1Linear_ad9ad1a3bdb0f3fff5c839ed155e4bbf8}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Backward@{Backward}}
\index{Backward@{Backward}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Backward()}
{\footnotesize\ttfamily void Backward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{gy,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{g }\end{DoxyParamCaption})}



Ordinary feed backward pass of a neural network, calculating the function f(x) by propagating x backwards trough f. 

Using the results from the feed forward pass.


\begin{DoxyParams}{Parameters}
{\em $\ast$} & (input) The propagated input activation. \\
\hline
{\em gy} & The backpropagated error. \\
\hline
{\em g} & The calculated gradient. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Linear_a5fc2a33fc7d5e99a69d1c1e59c405d46}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Bias@{Bias}}
\index{Bias@{Bias}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Bias()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Bias (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the bias of the layer. 



Definition at line 145 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a1bc54e7fd212b3479d8035871a1f060f}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Bias@{Bias}}
\index{Bias@{Bias}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Bias()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Bias (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the bias weights of the layer. 



Definition at line 147 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a797f7edb44dd081e5e2b3cc316eef6bd}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the delta. 



Definition at line 124 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_ad6601342d560219ce951d554e69e5e87}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Delta@{Delta}}
\index{Delta@{Delta}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Delta()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Delta (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the delta. 



Definition at line 126 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a461f849bc638c15bec262dc9c3a58abe}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Forward@{Forward}}
\index{Forward@{Forward}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Forward()}
{\footnotesize\ttfamily void Forward (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{output }\end{DoxyParamCaption})}



Ordinary feed forward pass of a neural network, evaluating the function f(x) by propagating the activity forward through f. 


\begin{DoxyParams}{Parameters}
{\em input} & Input data used for evaluating the specified function. \\
\hline
{\em output} & Resulting output activation. \\
\hline
\end{DoxyParams}
\mbox{\label{classmlpack_1_1ann_1_1Linear_aaf577db350e2130754490d8486fba215}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [1/3]}}
{\footnotesize\ttfamily void Gradient (\begin{DoxyParamCaption}\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{input,  }\item[{const arma\+::\+Mat$<$ eT $>$ \&}]{error,  }\item[{arma\+::\+Mat$<$ eT $>$ \&}]{gradient }\end{DoxyParamCaption})}

\mbox{\label{classmlpack_1_1ann_1_1Linear_a0f1f4e6d93472d83852731a96c8c3f59}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [2/3]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Gradient (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the gradient. 



Definition at line 135 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a19abce4739c3b0b658b612537e21956a}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Gradient@{Gradient}}
\index{Gradient@{Gradient}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Gradient()\hspace{0.1cm}{\footnotesize\ttfamily [3/3]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Gradient (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the gradient. 



Definition at line 137 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_aaffd593b3ab627f8b5aae2a1f53634b0}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Input\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Input\+Data\+Type const\& Input\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the input parameter. 



Definition at line 114 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a063c3b1053c7979a7dd2e7bbd2bf1f8a}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Input\+Parameter@{Input\+Parameter}}
\index{Input\+Parameter@{Input\+Parameter}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Input\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Input\+Data\+Type\& Input\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the input parameter. 



Definition at line 116 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a13ab93f234244a68f6ade76287284447}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Input\+Shape@{Input\+Shape}}
\index{Input\+Shape@{Input\+Shape}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Input\+Shape()}
{\footnotesize\ttfamily size\+\_\+t Input\+Shape (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the shape of the input. 



Definition at line 156 of file linear.\+hpp.



References Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$\+::serialize().

\mbox{\label{classmlpack_1_1ann_1_1Linear_a5a4c4984aa897a28d516e638e7ea5308}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Input\+Size@{Input\+Size}}
\index{Input\+Size@{Input\+Size}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Input\+Size()}
{\footnotesize\ttfamily size\+\_\+t Input\+Size (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the input size. 



Definition at line 129 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a1e7bfb69fbf11b6f8f6ebc5029ea5259}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!operator=@{operator=}}
\index{operator=@{operator=}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{operator=()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily \textbf{ Linear}\& operator= (\begin{DoxyParamCaption}\item[{const \textbf{ Linear}$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$ \&}]{layer }\end{DoxyParamCaption})}



Copy assignment operator. 

\mbox{\label{classmlpack_1_1ann_1_1Linear_ade97837b85bec38d5f87cf5147bdfeda}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!operator=@{operator=}}
\index{operator=@{operator=}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{operator=()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily \textbf{ Linear}\& operator= (\begin{DoxyParamCaption}\item[{\textbf{ Linear}$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$ \&\&}]{layer }\end{DoxyParamCaption})}



Move assignment operator. 

\mbox{\label{classmlpack_1_1ann_1_1Linear_a0ee21c2a36e5abad1e7a9d5dd00849f9}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Output\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the output parameter. 



Definition at line 119 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a21d5f745f02c709625a4ee0907f004a5}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Output\+Parameter@{Output\+Parameter}}
\index{Output\+Parameter@{Output\+Parameter}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Output\+Parameter()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Output\+Parameter (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the output parameter. 



Definition at line 121 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a99c1d948c984b9e76fb5e37e2145427a}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Output\+Size@{Output\+Size}}
\index{Output\+Size@{Output\+Size}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Output\+Size()}
{\footnotesize\ttfamily size\+\_\+t Output\+Size (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the output size. 



Definition at line 132 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_aa530552c7ef915c952fbacc77b965c90}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the parameters. 



Definition at line 109 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a9c5c5900772a689d5a6b59778ec67120}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Parameters@{Parameters}}
\index{Parameters@{Parameters}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Parameters()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Parameters (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the parameters. 



Definition at line 111 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a372de693ad40b3f42839c8ec6ac845f4}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Reset@{Reset}}
\index{Reset@{Reset}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Reset()}
{\footnotesize\ttfamily void Reset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

\mbox{\label{classmlpack_1_1ann_1_1Linear_a65cba07328997659bec80b9879b15a51}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!serialize@{serialize}}
\index{serialize@{serialize}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{serialize()}
{\footnotesize\ttfamily void serialize (\begin{DoxyParamCaption}\item[{Archive \&}]{ar,  }\item[{const uint32\+\_\+t}]{ }\end{DoxyParamCaption})}



Serialize the layer. 



Referenced by Linear$<$ Input\+Data\+Type, Output\+Data\+Type, Regularizer\+Type $>$\+::\+Input\+Shape().

\mbox{\label{classmlpack_1_1ann_1_1Linear_a228fcfbfb2e9a4291426706ca9ba4894}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Weight@{Weight}}
\index{Weight@{Weight}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Weight()\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Output\+Data\+Type const\& Weight (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the weight of the layer. 



Definition at line 140 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a5016884f99089a4fc5da2468cce1ee2c}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Weight@{Weight}}
\index{Weight@{Weight}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Weight()\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Output\+Data\+Type\& Weight (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Modify the weight of the layer. 



Definition at line 142 of file linear.\+hpp.

\mbox{\label{classmlpack_1_1ann_1_1Linear_a7a2704698a50d9e00dfb083f3a863579}} 
\index{mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}!Weight\+Size@{Weight\+Size}}
\index{Weight\+Size@{Weight\+Size}!mlpack\+::ann\+::\+Linear@{mlpack\+::ann\+::\+Linear}}
\subsubsection{Weight\+Size()}
{\footnotesize\ttfamily size\+\_\+t Weight\+Size (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}}



Get the size of the weights. 



Definition at line 150 of file linear.\+hpp.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/ann/layer/\textbf{ layer\+\_\+types.\+hpp}\item 
/home/aakash/mlpack/src/mlpack/methods/ann/layer/\textbf{ linear.\+hpp}\end{DoxyCompactItemize}
