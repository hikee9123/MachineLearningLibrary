<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>mlpack: Cross-Validation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra-stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">3.4.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Cross-Validation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="cvintro"></a>
Introduction</h1>
<p><b>mlpack</b> implements cross-validation support for its learning algorithms, for a variety of performance measures. Cross-validation is useful for determining an estimate of how well the learner will generalize to un-seen test data. It is a commonly used part of the data science pipeline.</p>
<p>In short, given some learner and some performance measure, we wish to get an average of the performance measure given different splits of the dataset into training data and validation data. The learner is trained on the training data, and the performance measure is evaluated on the validation data.</p>
<p>mlpack currently implements two easy-to-use forms of cross-validation:</p>
<ul>
<li><b>simple</b> <b>cross-validation</b>, where we simply desire the performance measure on a single split of the data into a training set and validation set</li>
<li><b>k-fold</b> <b>cross-validation</b>, where we split the data k ways and desire the average performance measure on each of the k splits of the data</li>
</ul>
<p>In this tutorial we will see the usage examples and details of the cross-validation module. Because the cross-validation code is generic and can be used with any learner and performance measure, any use of the cross-validation code in mlpack has to be in C++.</p>
<p>This tutorial is split into the following sections:</p>
<ul>
<li><a class="el" href="cv.html#cvbasic">Simple cross-validation examples</a> Simple cross-validation examples<ul>
<li><a class="el" href="cv.html#cvbasic_ex_1">10-fold cross-validation on softmax regression</a> 10-fold cross-validation on softmax regression</li>
<li><a class="el" href="cv.html#cvbasic_ex_2">10-fold cross-validation on weighted decision trees</a> 10-fold cross-validation on weighted decision trees</li>
<li><a class="el" href="cv.html#cvbasic_ex_3">10-fold cross-validation with categorical decision trees</a> 10-fold cross-validation with categorical decision trees</li>
<li><a class="el" href="cv.html#cvbasic_ex_4">Simple cross-validation for linear regression</a> Simple cross-validation for linear regression</li>
</ul>
</li>
<li><a class="el" href="cv.html#cvbasic_metrics">Performance measures</a> Performance measures</li>
<li><a class="el" href="cv.html#cvbasic_api">The KFoldCV and SimpleCV classes</a> The <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> and <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> classes</li>
<li><a class="el" href="cv.html#cvbasic_further">Further references</a> Further reference</li>
</ul>
<h1><a class="anchor" id="cvbasic"></a>
Simple cross-validation examples</h1>
<h2><a class="anchor" id="cvbasic_ex_1"></a>
10-fold cross-validation on softmax regression</h2>
<p>Suppose we have some data to train and validate on, as defined below:</p>
<div class="fragment"><div class="line"><span class="comment">// 100-point 6-dimensional random dataset.</span></div><div class="line">arma::mat data = arma::randu&lt;arma::mat&gt;(6, 100);</div><div class="line"><span class="comment">// Random labels in the [0, 4] interval.</span></div><div class="line">arma::Row&lt;size_t&gt; labels =</div><div class="line">    arma::randi&lt;arma::Row&lt;size_t&gt;&gt;(100, arma::distr_param(0, 4));</div><div class="line"><span class="keywordtype">size_t</span> numClasses = 5;</div></div><!-- fragment --><p>The code above generates an 100-point random 6-dimensional dataset with 5 classes.</p>
<p>To run 10-fold cross-validation for softmax regression with accuracy as a performance measure, we can write the following piece of code.</p>
<div class="fragment"><div class="line">KFoldCV&lt;SoftmaxRegression, Accuracy&gt; cv(10, data, labels, numClasses);</div><div class="line"><span class="keywordtype">double</span> lambda = 0.1;</div><div class="line"><span class="keywordtype">double</span> softmaxAccuracy = cv.Evaluate(lambda);</div></div><!-- fragment --><p>Note that the <code>Evaluate</code> method of <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> takes any hyperparameters of an algorithm&mdash;that is, anything that is not <code>data</code>, <code>labels</code>, <code>numClasses</code>, <code>datasetInfo</code>, or <code>weights</code> (those last three may not be present for every algorithm type). To be more specific, in this example the <code>Evaluate</code> method relies on the following <a class="el" href="classmlpack_1_1regression_1_1SoftmaxRegression.html">SoftmaxRegression</a> constructor:</p>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> OptimizerType = mlpack::optimization::L_BFGS&gt;</div><div class="line">SoftmaxRegression(<span class="keyword">const</span> arma::mat&amp; data,</div><div class="line">                  <span class="keyword">const</span> arma::Row&lt;size_t&gt;&amp; labels,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">size_t</span> numClasses,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">double</span> lambda = 0.0001,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">bool</span> fitIntercept = <span class="keyword">false</span>,</div><div class="line">                  OptimizerType optimizer = OptimizerType());</div></div><!-- fragment --><p>which has the parameter <code>lambda</code> after three conventional arguments (<code>data</code>, <code>labels</code> and <code>numClasses</code>). We can skip passing <code>fitIntercept</code> and <code>optimizer</code> since there are the default values. (Technically, we don't even need to pass <code>lambda</code> since there is a default value.)</p>
<p>In general to cross-validate you need to specify what machine learning algorithm and metric you are going to use, and then to pass some conventional data-related parameters into one of the cross-validation constructors and all other parameters (which are generally hyperparameters) into the <code>Evaluate</code> method.</p>
<h2><a class="anchor" id="cvbasic_ex_2"></a>
10-fold cross-validation on weighted decision trees</h2>
<p>In the following example we will cross-validate <a class="el" href="classmlpack_1_1tree_1_1DecisionTree.html">DecisionTree</a> with weights. This is very similar to the previous example, except that we also have instance weights for each point in the dataset. We can generate weights for the dataset from the previous example with the code below:</p>
<div class="fragment"><div class="line"><span class="comment">// Random weights for every point from the code snippet above.</span></div><div class="line">arma::rowvec weights = arma::randu&lt;arma::mat&gt;(1, 100);</div></div><!-- fragment --><p>Given those weights for each point, we can now perform cross-validation by also passing the weights to the constructor of <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a>:</code> </p>
<div class="fragment"><div class="line">KFoldCV&lt;DecisionTree&lt;&gt;, Accuracy&gt; cv2(10, data, labels, numClasses, weights);</div><div class="line"><span class="keywordtype">size_t</span> minimumLeafSize = 8;</div><div class="line"><span class="keywordtype">double</span> weightedDecisionTreeAccuracy = cv2.Evaluate(minimumLeafSize);</div></div><!-- fragment --><p>As with the previous example, internally this call to <code>cv2.Evaluate()</code> relies on the following <a class="el" href="classmlpack_1_1tree_1_1DecisionTree.html">DecisionTree</a> constructor:</p>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> MatType, <span class="keyword">typename</span> LabelsType, <span class="keyword">typename</span> WeightsType&gt;</div><div class="line">DecisionTree(MatType&amp;&amp; data,</div><div class="line">             LabelsType&amp;&amp; labels,</div><div class="line">             <span class="keyword">const</span> <span class="keywordtype">size_t</span> numClasses,</div><div class="line">             WeightsType&amp;&amp; weights,</div><div class="line">             <span class="keyword">const</span> <span class="keywordtype">size_t</span> minimumLeafSize = 10,</div><div class="line">             <span class="keyword">const</span> <a class="code" href="namespacestd.html#a93e9cb7fadbcfaa2afb5b94058b8e34c">std::enable_if_t</a>&lt;arma::is_arma_type&lt;</div><div class="line">                 <span class="keyword">typename</span> std::remove_reference&lt;WeightsType&gt;::type&gt;::value&gt;*</div><div class="line">                  = 0);</div></div><!-- fragment --><h2><a class="anchor" id="cvbasic_ex_3"></a>
10-fold cross-validation with categorical decision trees</h2>
<p><a class="el" href="classmlpack_1_1tree_1_1DecisionTree.html">DecisionTree</a> models can be constructed in multiple other ways. For example, if we have a dataset with both categorical and numerical features, we can also perform cross-validation by using the associated <code><a class="el" href="namespacemlpack_1_1data.html#aa243ad7e4d29363b858bbc92b732921d">data::DatasetInfo</a></code> object. Thus, given some <code><a class="el" href="namespacemlpack_1_1data.html#aa243ad7e4d29363b858bbc92b732921d">data::DatasetInfo</a></code> object called <code>datasetInfo</code> (that perhaps was produced by a call to <code><a class="el" href="namespacemlpack_1_1data.html#abbff2a667bf247e00b1fc09b7ca5f831" title="Loads a matrix from file, guessing the filetype from the extension. ">data::Load()</a></code> ), we can perform k-fold cross-validation in a similar manner to the other examples:</p>
<div class="fragment"><div class="line">KFoldCV&lt;DecisionTree&lt;&gt;, Accuracy&gt; cv3(10, data, datasetInfo, labels,</div><div class="line">    numClasses);</div><div class="line"><span class="keywordtype">double</span> decisionTreeWithDIAccuracy = cv3.Evaluate(minimumLeafSize);</div></div><!-- fragment --><p>This particular call to <code>cv3.Evaluate()</code> relies on the following <a class="el" href="classmlpack_1_1tree_1_1DecisionTree.html">DecisionTree</a> constructor:</p>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> MatType, <span class="keyword">typename</span> LabelsType&gt;</div><div class="line">DecisionTree(MatType&amp;&amp; data,</div><div class="line">             <span class="keyword">const</span> <a class="code" href="namespacemlpack_1_1data.html#aa243ad7e4d29363b858bbc92b732921d">data::DatasetInfo</a>&amp; datasetInfo,</div><div class="line">             LabelsType&amp;&amp; labels,</div><div class="line">             <span class="keyword">const</span> <span class="keywordtype">size_t</span> numClasses,</div><div class="line">             <span class="keyword">const</span> <span class="keywordtype">size_t</span> minimumLeafSize = 10);</div></div><!-- fragment --><h2><a class="anchor" id="cvbasic_ex_4"></a>
Simple cross-validation for linear regression</h2>
<p><code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> has the same interface as <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code>, except it takes as one of its arguments a proportion (from 0 to 1) of data used as a validation set. For example, to validate <a class="el" href="classmlpack_1_1regression_1_1LinearRegression.html">LinearRegression</a> with 20% of the data used in the validation set we can write the following code.</p>
<div class="fragment"><div class="line"><span class="comment">// Random responses for every point from the code snippet in the beginning of</span></div><div class="line"><span class="comment">// the tutorial.</span></div><div class="line">arma::rowvec responses = arma::randu&lt;arma::rowvec&gt;(100);</div><div class="line"></div><div class="line">SimpleCV&lt;LinearRegression, MSE&gt; cv4(0.2, data, responses);</div><div class="line"><span class="keywordtype">double</span> lrLambda = 0.05;</div><div class="line"><span class="keywordtype">double</span> lrMSE = cv4.Evaluate(lrLambda);</div></div><!-- fragment --><h1><a class="anchor" id="cvbasic_metrics"></a>
Performance measures</h1>
<p>The cross-validation classes require a performance measure to be specified. <b>mlpack</b> has a number of performance measures implemented; below is a list:</p>
<ul>
<li><a class="el" href="classmlpack_1_1cv_1_1Accuracy.html" title="The Accuracy is a metric of performance for classification algorithms that is equal to a proportion o...">mlpack::cv::Accuracy</a>: a simple measure of accuracy</li>
<li><a class="el" href="classmlpack_1_1cv_1_1F1.html" title="F1 is a metric of performance for classification algorithms that for binary classification is equal t...">mlpack::cv::F1</a>: the <a class="el" href="classmlpack_1_1cv_1_1F1.html" title="F1 is a metric of performance for classification algorithms that for binary classification is equal t...">F1</a> score; depends on an averaging strategy</li>
<li><a class="el" href="classmlpack_1_1cv_1_1MSE.html" title="The MeanSquaredError is a metric of performance for regression algorithms that is equal to the mean s...">mlpack::cv::MSE</a>: minimum squared error (for regression problems)</li>
<li><a class="el" href="classmlpack_1_1cv_1_1Precision.html" title="Precision is a metric of performance for classification algorithms that for binary classification is ...">mlpack::cv::Precision</a>: the precision, for classification problems</li>
<li><a class="el" href="classmlpack_1_1cv_1_1Recall.html" title="Recall is a metric of performance for classification algorithms that for binary classification is equ...">mlpack::cv::Recall</a>: the recall, for classification problems</li>
</ul>
<p>In addition, it is not difficult to implement a custom performance measure. A class following the structure below can be used:</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>CustomMeasure</div><div class="line">{</div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// This evaluates the metric given a trained model and a set of data (with</span></div><div class="line">  <span class="comment">// labels or responses) to evaluate on.  The data parameter will be a type of</span></div><div class="line">  <span class="comment">// Armadillo matrix, and the labels will be the labels that go with the model.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// If you know that your model is a classification model (and thus that</span></div><div class="line">  <span class="comment">// ResponsesType will be arma::Row&lt;size_t&gt;), it is ok to replace the</span></div><div class="line">  <span class="comment">// ResponsesType template parameter with arma::Row&lt;size_t&gt;.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> MLAlgorithm, <span class="keyword">typename</span> DataType, <span class="keyword">typename</span> ResponsesType&gt;</div><div class="line">  <span class="keyword">static</span> <span class="keywordtype">double</span> Evaluate(MLAlgorithm&amp; model,</div><div class="line">                         <span class="keyword">const</span> DataType&amp; data,</div><div class="line">                         <span class="keyword">const</span> ResponsesType&amp; labels)</div><div class="line">  {</div><div class="line">    <span class="comment">// Inside the method you should call model.Predict() and compare the</span></div><div class="line">    <span class="comment">// values with the labels, in order to get the desired performance measure</span></div><div class="line">    <span class="comment">// and return it.</span></div><div class="line">  }</div><div class="line">};</div></div><!-- fragment --><p>Once this is implemented, then <code>CustomMeasure</code> (or whatever the class is called) is easy to use as a custom performance measure with <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> or <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code>.</p>
<h1><a class="anchor" id="cvbasic_api"></a>
The KFoldCV and SimpleCV classes</h1>
<p>This section provides details about the <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> and <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> classes. The cross-validation infrastructure is based on heavy amounts of template metaprogramming, so that any <b>mlpack</b> learner and any performance measure can be used. Both classes have two required template parameters and one optional parameter:</p>
<ul>
<li><code>MLAlgorithm:</code> the type of learner to be used</li>
<li><code>Metric:</code> the performance measure to be evaluated</li>
<li><code>MatType:</code> the type of matrix used to store the data</li>
</ul>
<p>In addition, there are two more template parameters, but these are automatically extracted from the given <code>MLAlgorithm</code> class, and users should not need to specify these parameters except when using an unconventional type like <code>arma::fmat</code> for data points.</p>
<p>The general structure of the <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> and <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> classes is split into two parts:</p>
<ul>
<li>The constructor: create the object, and store the data for the <code>MLAlgorithm</code> training.</li>
<li>The <code>Evaluate()</code> method: take any non-data parameters for the <code>MLAlgorithm</code> and calculate the desired performance measure.</li>
</ul>
<p>This split is important because it defines the API: all data-related parameters are passed to the constructor, whereas algorithm hyperparameters are passed to the <code>Evaluate()</code> method.</p>
<h2><a class="anchor" id="cvbasic_api_constructor"></a>
The KFoldCV and SimpleCV constructors</h2>
<p>There are six constructors available for <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> and <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code>, each tailored for a different learning situation. Each is given below for the <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> class, but the same constructors are also available for the <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> class, with the exception that instead of specifying <code>k</code>, the number of folds, the <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> class takes a parameter between 0 and 1 specifying the percentage of the dataset to use as a validation set.</p>
<ul>
<li><code>KFoldCV(k, xs, ys)</code>: this is for unweighted regression applications and two-class classification applications; <code>xs</code> is the dataset and <code>ys</code> are the responses or labels for each point in the dataset.</li>
<li><code>KFoldCV(k, xs, ys, numClasses)</code>: this is for unweighted classification applications; <code>xs</code> is the dataset, <code>ys</code> are the class labels for each data point, and <code>numClasses</code> is the number of classes in the dataset.</li>
<li><code>KFoldCV(k, xs, datasetInfo, ys, numClasses)</code>: this is for unweighted categorical/numeric classification applications; <code>xs</code> is the dataset, <code>datasetInfo</code> is a <a class="el" href="namespacemlpack_1_1data.html#aa243ad7e4d29363b858bbc92b732921d">data::DatasetInfo</a> object that holds the types of each dimension in the dataset, <code>ys</code> are the class labels for each data point, and <code>numClasses</code> is the number of classes in the dataset.</li>
<li><code>KFoldCV(k, xs, ys, weights)</code>: this is for weighted regression or two-class classification applications; <code>xs</code> is the dataset, <code>ys</code> are the responses or labels for each point in the dataset, and <code>weights</code> are the weights for each point in the dataset.</li>
<li><code>KFoldCV(k, xs, ys, numClasses, weights)</code>: this is for weighted classification applications; <code>xs</code> is the dataset, <code>ys</code> are the class labels for each point in the dataset; <code>numClasses</code> is the number of classes in the dataset, and <code>weights</code> holds the weights for each point in the dataset.</li>
<li><code>KFoldCV(k, xs, datasetInfo, ys, numClasses, weights)</code>: this is for weighted cateogrical/numeric classification applications; <code>xs</code> is the dataset, <code>datasetInfo</code> is a <a class="el" href="namespacemlpack_1_1data.html#aa243ad7e4d29363b858bbc92b732921d">data::DatasetInfo</a> object that holds the types of each dimension in the dataset, <code>ys</code> are the class labels for each data point, <code>numClasses</code> is the number of classes in each dataset, and <code>weights</code> holds the weights for each point in the dataset.</li>
</ul>
<p>Note that the constructor you should use is the constructor that most closely matches the constructor of the machine learning algorithm you would like performance measures of. So, for instance, if you are doing multi-class softmax regression, you could call the constructor <code>"SoftmaxRegression(xs, ys, numClasses)"</code>. Therefore, for <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> you would call the constructor <code>"KFoldCV(k, xs, ys, numClasses)"</code> and for <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> you would call the constructor <code>"SimpleCV(pct, xs, ys, numClasses)"</code>.</p>
<h2><a class="anchor" id="cvbasic_api_evaluate"></a>
The Evaluate() method</h2>
<p>The other method that <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> and <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code> have is the method to actually calculate the performance measure: <code>Evaluate()</code>. The <code>Evaluate()</code> method takes any hyperparameters that would follow the data arguments to the constructor or <code>Train()</code> method of the given <code>MLAlgorithm</code>. The <code>Evaluate()</code> method takes no more arguments than that, and returns the desired performance measure on the dataset.</p>
<p>Therefore, let us suppose that we are interested in cross-validating the performance of a softmax regression model, and that we have constructed the appropriate <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> object using the code below:</p>
<div class="fragment"><div class="line">KFoldCV&lt;SoftmaxRegression, Precision&gt; cv(k, data, labels, numClasses);</div></div><!-- fragment --><p>The <a class="el" href="classmlpack_1_1regression_1_1SoftmaxRegression.html">SoftmaxRegression</a> class has the constructor</p>
<div class="fragment"><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> OptimizerType = mlpack::optimization::L_BFGS&gt;</div><div class="line">SoftmaxRegression(<span class="keyword">const</span> arma::mat&amp; data,</div><div class="line">                  <span class="keyword">const</span> arma::Row&lt;size_t&gt;&amp; labels,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">size_t</span> numClasses,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">double</span> lambda = 0.0001,</div><div class="line">                  <span class="keyword">const</span> <span class="keywordtype">bool</span> fitIntercept = <span class="keyword">false</span>,</div><div class="line">                  OptimizerType optimizer = OptimizerType());</div></div><!-- fragment --><p>Note that all parameters after are <code>numClasses</code> are optional. This means that we can specify none or any of them in our call to <code>Evaluate()</code>. Below is some example code showing three different ways we can call <code>Evaluate()</code> with the <code>cv</code> object from the code snippet above.</p>
<div class="fragment"><div class="line"><span class="comment">// First, call with all defaults.</span></div><div class="line"><span class="keywordtype">double</span> result1 = cv.Evaluate();</div><div class="line"></div><div class="line"><span class="comment">// Next, call with lambda set to 0.1 and fitIntercept set to true.</span></div><div class="line"><span class="keywordtype">double</span> result2 = cv.Evaluate(0.1, <span class="keyword">true</span>);</div><div class="line"></div><div class="line"><span class="comment">// Lastly, create a custom optimizer to use for optimization, and use a lambda</span></div><div class="line"><span class="comment">// value of 0.5 and fit no intercept.</span></div><div class="line">optimization::SGD&lt;&gt; sgd(0.05, 50000); <span class="comment">// Step size of 0.05, 50k max iterations.</span></div><div class="line"><span class="keywordtype">double</span> result3 = cv.Evaluate(0.5, <span class="keyword">false</span>, sgd);</div></div><!-- fragment --><p>The same general idea applies to any <code>MLAlgorithm:</code> all hyperparameters must be passed to the <code>Evaluate()</code> method of <code><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">KFoldCV</a></code> or <code><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">SimpleCV</a></code>.</p>
<h1><a class="anchor" id="cvbasic_further"></a>
Further references</h1>
<p>For further documentation, please see the associated Doxygen documentation for each of the relevant classes:</p>
<ul>
<li><a class="el" href="classmlpack_1_1cv_1_1SimpleCV.html" title="SimpleCV splits data into two sets - training and validation sets - and then runs training on the tra...">mlpack::cv::SimpleCV</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1KFoldCV.html" title="The class KFoldCV implements k-fold cross-validation for regression and classification algorithms...">mlpack::cv::KFoldCV</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1Accuracy.html" title="The Accuracy is a metric of performance for classification algorithms that is equal to a proportion o...">mlpack::cv::Accuracy</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1F1.html" title="F1 is a metric of performance for classification algorithms that for binary classification is equal t...">mlpack::cv::F1</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1MSE.html" title="The MeanSquaredError is a metric of performance for regression algorithms that is equal to the mean s...">mlpack::cv::MSE</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1Precision.html" title="Precision is a metric of performance for classification algorithms that for binary classification is ...">mlpack::cv::Precision</a></li>
<li><a class="el" href="classmlpack_1_1cv_1_1Recall.html" title="Recall is a metric of performance for classification algorithms that for binary classification is equ...">mlpack::cv::Recall</a></li>
</ul>
<p>If you are interested in implementing a different cross-validation strategy than k-fold cross-validation or simple cross-validation, take a look at the implementations of each of those classes to guide your implementation.</p>
<p>In addition, the <a class="el" href="namespacemlpack_1_1hpt.html">hyperparameter tuner</a> documentation may also be relevant. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>
