<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>mlpack: SAC&lt; EnvironmentType, QNetworkType, PolicyNetworkType, UpdaterType, ReplayType &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra-stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">3.4.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacemlpack.html">mlpack</a></li><li class="navelem"><a class="el" href="namespacemlpack_1_1rl.html">rl</a></li><li class="navelem"><a class="el" href="classmlpack_1_1rl_1_1SAC.html">SAC</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classmlpack_1_1rl_1_1SAC-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">SAC&lt; EnvironmentType, QNetworkType, PolicyNetworkType, UpdaterType, ReplayType &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Implementation of Soft Actor-Critic, a model-free off-policy actor-critic based deep reinforcement learning algorithm.  
 <a href="classmlpack_1_1rl_1_1SAC.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:aaf7b2dc5d49d01961601c7c16be76777"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#aaf7b2dc5d49d01961601c7c16be76777">ActionType</a> = typename EnvironmentType::Action</td></tr>
<tr class="memdesc:aaf7b2dc5d49d01961601c7c16be76777"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convenient typedef for action.  <a href="#aaf7b2dc5d49d01961601c7c16be76777">More...</a><br /></td></tr>
<tr class="separator:aaf7b2dc5d49d01961601c7c16be76777"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada68ef405b7c331a2bee337614f00088"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a> = typename EnvironmentType::State</td></tr>
<tr class="memdesc:ada68ef405b7c331a2bee337614f00088"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convenient typedef for state.  <a href="#ada68ef405b7c331a2bee337614f00088">More...</a><br /></td></tr>
<tr class="separator:ada68ef405b7c331a2bee337614f00088"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a382013c48f00c0cd5e682edb92a01f16"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a382013c48f00c0cd5e682edb92a01f16">SAC</a> (<a class="el" href="classmlpack_1_1rl_1_1TrainingConfig.html">TrainingConfig</a> &amp;config, QNetworkType &amp;learningQ1Network, PolicyNetworkType &amp;policyNetwork, ReplayType &amp;replayMethod, UpdaterType qNetworkUpdater=UpdaterType(), UpdaterType policyNetworkUpdater=UpdaterType(), EnvironmentType environment=EnvironmentType())</td></tr>
<tr class="memdesc:a382013c48f00c0cd5e682edb92a01f16"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create the <a class="el" href="classmlpack_1_1rl_1_1SAC.html" title="Implementation of Soft Actor-Critic, a model-free off-policy actor-critic based deep reinforcement le...">SAC</a> object with given settings.  <a href="#a382013c48f00c0cd5e682edb92a01f16">More...</a><br /></td></tr>
<tr class="separator:a382013c48f00c0cd5e682edb92a01f16"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf0c5202e5e579fc47c332f2490fbb8f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#abf0c5202e5e579fc47c332f2490fbb8f">~SAC</a> ()</td></tr>
<tr class="memdesc:abf0c5202e5e579fc47c332f2490fbb8f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Clean memory.  <a href="#abf0c5202e5e579fc47c332f2490fbb8f">More...</a><br /></td></tr>
<tr class="separator:abf0c5202e5e579fc47c332f2490fbb8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d32caed9517e5d2014238a22f78352d"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classmlpack_1_1rl_1_1SAC.html#aaf7b2dc5d49d01961601c7c16be76777">ActionType</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a0d32caed9517e5d2014238a22f78352d">Action</a> () const</td></tr>
<tr class="memdesc:a0d32caed9517e5d2014238a22f78352d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the action of the agent.  <a href="#a0d32caed9517e5d2014238a22f78352d">More...</a><br /></td></tr>
<tr class="separator:a0d32caed9517e5d2014238a22f78352d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42d4ee3da432cff20d3a41b8b1ec801c"><td class="memItemLeft" align="right" valign="top">bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a42d4ee3da432cff20d3a41b8b1ec801c">Deterministic</a> ()</td></tr>
<tr class="memdesc:a42d4ee3da432cff20d3a41b8b1ec801c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the training mode / test mode indicator.  <a href="#a42d4ee3da432cff20d3a41b8b1ec801c">More...</a><br /></td></tr>
<tr class="separator:a42d4ee3da432cff20d3a41b8b1ec801c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d262f7871c5cc8b532971fb644f0abf"><td class="memItemLeft" align="right" valign="top">const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a5d262f7871c5cc8b532971fb644f0abf">Deterministic</a> () const</td></tr>
<tr class="memdesc:a5d262f7871c5cc8b532971fb644f0abf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the indicator of training mode / test mode.  <a href="#a5d262f7871c5cc8b532971fb644f0abf">More...</a><br /></td></tr>
<tr class="separator:a5d262f7871c5cc8b532971fb644f0abf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fb26736f2d90010f882f9628cd26612"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a1fb26736f2d90010f882f9628cd26612">Episode</a> ()</td></tr>
<tr class="memdesc:a1fb26736f2d90010f882f9628cd26612"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute an episode.  <a href="#a1fb26736f2d90010f882f9628cd26612">More...</a><br /></td></tr>
<tr class="separator:a1fb26736f2d90010f882f9628cd26612"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd126acd7f564c8326dc765232624ae4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#abd126acd7f564c8326dc765232624ae4">SelectAction</a> ()</td></tr>
<tr class="memdesc:abd126acd7f564c8326dc765232624ae4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Select an action, given an agent.  <a href="#abd126acd7f564c8326dc765232624ae4">More...</a><br /></td></tr>
<tr class="separator:abd126acd7f564c8326dc765232624ae4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e8b07b1eb04d72c36e95f795340d5c6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a0e8b07b1eb04d72c36e95f795340d5c6">SoftUpdate</a> (double rho)</td></tr>
<tr class="memdesc:a0e8b07b1eb04d72c36e95f795340d5c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Softly update the learning Q network parameters to the target Q network parameters.  <a href="#a0e8b07b1eb04d72c36e95f795340d5c6">More...</a><br /></td></tr>
<tr class="separator:a0e8b07b1eb04d72c36e95f795340d5c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7a595de4a1a67da528603c20f80315f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#ad7a595de4a1a67da528603c20f80315f">State</a> ()</td></tr>
<tr class="memdesc:ad7a595de4a1a67da528603c20f80315f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the state of the agent.  <a href="#ad7a595de4a1a67da528603c20f80315f">More...</a><br /></td></tr>
<tr class="separator:ad7a595de4a1a67da528603c20f80315f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa3e388ae5e024c8ec49fd4d1ef725ad"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#afa3e388ae5e024c8ec49fd4d1ef725ad">State</a> () const</td></tr>
<tr class="memdesc:afa3e388ae5e024c8ec49fd4d1ef725ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the state of the agent.  <a href="#afa3e388ae5e024c8ec49fd4d1ef725ad">More...</a><br /></td></tr>
<tr class="separator:afa3e388ae5e024c8ec49fd4d1ef725ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaf0bb243c2e643c57654b8e65058fa0"><td class="memItemLeft" align="right" valign="top">size_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#abaf0bb243c2e643c57654b8e65058fa0">TotalSteps</a> ()</td></tr>
<tr class="memdesc:abaf0bb243c2e643c57654b8e65058fa0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify total steps from beginning.  <a href="#abaf0bb243c2e643c57654b8e65058fa0">More...</a><br /></td></tr>
<tr class="separator:abaf0bb243c2e643c57654b8e65058fa0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a689af4e6e564ab01f40e6ec49638bdaf"><td class="memItemLeft" align="right" valign="top">const size_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#a689af4e6e564ab01f40e6ec49638bdaf">TotalSteps</a> () const</td></tr>
<tr class="memdesc:a689af4e6e564ab01f40e6ec49638bdaf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get total steps from beginning.  <a href="#a689af4e6e564ab01f40e6ec49638bdaf">More...</a><br /></td></tr>
<tr class="separator:a689af4e6e564ab01f40e6ec49638bdaf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec0783b5a136e042adcc47bae4fe5291"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#aec0783b5a136e042adcc47bae4fe5291">Update</a> ()</td></tr>
<tr class="memdesc:aec0783b5a136e042adcc47bae4fe5291"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the Q and policy networks.  <a href="#aec0783b5a136e042adcc47bae4fe5291">More...</a><br /></td></tr>
<tr class="separator:aec0783b5a136e042adcc47bae4fe5291"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename EnvironmentType, typename QNetworkType, typename PolicyNetworkType, typename UpdaterType, typename ReplayType = RandomReplay&lt;EnvironmentType&gt;&gt;<br />
class mlpack::rl::SAC&lt; EnvironmentType, QNetworkType, PolicyNetworkType, UpdaterType, ReplayType &gt;</h3>

<p>Implementation of Soft Actor-Critic, a model-free off-policy actor-critic based deep reinforcement learning algorithm. </p>
<p>For more details, see the following: </p><div class="fragment"><div class="line">@misc{haarnoja2018soft,</div><div class="line"> author    = {Tuomas Haarnoja and</div><div class="line">              Aurick Zhou and</div><div class="line">              Kristian Hartikainen and</div><div class="line">              George Tucker and</div><div class="line">              Sehoon Ha and</div><div class="line">              Jie Tan and</div><div class="line">              Vikash Kumar and</div><div class="line">              Henry Zhu and</div><div class="line">              Abhishek Gupta and</div><div class="line">              Pieter Abbeel and</div><div class="line">              Sergey Levine},</div><div class="line"> title     = {Soft Actor-Critic Algorithms and Applications},</div><div class="line"> year      = {2018},</div><div class="line"> url       = {https:<span class="comment">//arxiv.org/abs/1812.05905}</span></div><div class="line">}</div></div><!-- fragment --><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">EnvironmentType</td><td>The environment of the reinforcement learning task. </td></tr>
    <tr><td class="paramname">NetworkType</td><td>The network to compute action value. </td></tr>
    <tr><td class="paramname">UpdaterType</td><td>How to apply gradients when training. </td></tr>
    <tr><td class="paramname">ReplayType</td><td>Experience replay method. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00063">63</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="aaf7b2dc5d49d01961601c7c16be76777"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf7b2dc5d49d01961601c7c16be76777">&#9670;&nbsp;</a></span>ActionType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classmlpack_1_1rl_1_1SAC.html#aaf7b2dc5d49d01961601c7c16be76777">ActionType</a> =  typename EnvironmentType::Action</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Convenient typedef for action. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00070">70</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="ada68ef405b7c331a2bee337614f00088"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada68ef405b7c331a2bee337614f00088">&#9670;&nbsp;</a></span>StateType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a> =  typename EnvironmentType::State</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Convenient typedef for state. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00067">67</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a382013c48f00c0cd5e682edb92a01f16"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a382013c48f00c0cd5e682edb92a01f16">&#9670;&nbsp;</a></span>SAC()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlpack_1_1rl_1_1SAC.html">SAC</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlpack_1_1rl_1_1TrainingConfig.html">TrainingConfig</a> &amp;&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">QNetworkType &amp;&#160;</td>
          <td class="paramname"><em>learningQ1Network</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">PolicyNetworkType &amp;&#160;</td>
          <td class="paramname"><em>policyNetwork</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ReplayType &amp;&#160;</td>
          <td class="paramname"><em>replayMethod</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UpdaterType&#160;</td>
          <td class="paramname"><em>qNetworkUpdater</em> = <code>UpdaterType()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">UpdaterType&#160;</td>
          <td class="paramname"><em>policyNetworkUpdater</em> = <code>UpdaterType()</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">EnvironmentType&#160;</td>
          <td class="paramname"><em>environment</em> = <code>EnvironmentType()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create the <a class="el" href="classmlpack_1_1rl_1_1SAC.html" title="Implementation of Soft Actor-Critic, a model-free off-policy actor-critic based deep reinforcement le...">SAC</a> object with given settings. </p>
<p>If you want to pass in a parameter and discard the original parameter object, you can directly pass the parameter, as the constructor takes a reference. This avoids unnecessary copy.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">config</td><td>Hyper-parameters for training. </td></tr>
    <tr><td class="paramname">learningQ1Network</td><td>The network to compute action value. </td></tr>
    <tr><td class="paramname">policyNetwork</td><td>The network to produce an action given a state. </td></tr>
    <tr><td class="paramname">replayMethod</td><td>Experience replay method. </td></tr>
    <tr><td class="paramname">qNetworkUpdater</td><td>How to apply gradients to Q network when training. </td></tr>
    <tr><td class="paramname">policyNetworkUpdater</td><td>How to apply gradients to policy network when training. </td></tr>
    <tr><td class="paramname">environment</td><td>Reinforcement learning task. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="abf0c5202e5e579fc47c332f2490fbb8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf0c5202e5e579fc47c332f2490fbb8f">&#9670;&nbsp;</a></span>~SAC()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">~<a class="el" href="classmlpack_1_1rl_1_1SAC.html">SAC</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Clean memory. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a0d32caed9517e5d2014238a22f78352d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d32caed9517e5d2014238a22f78352d">&#9670;&nbsp;</a></span>Action()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classmlpack_1_1rl_1_1SAC.html#aaf7b2dc5d49d01961601c7c16be76777">ActionType</a>&amp; Action </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the action of the agent. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00136">136</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="a42d4ee3da432cff20d3a41b8b1ec801c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42d4ee3da432cff20d3a41b8b1ec801c">&#9670;&nbsp;</a></span>Deterministic() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool&amp; Deterministic </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Modify the training mode / test mode indicator. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00139">139</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="a5d262f7871c5cc8b532971fb644f0abf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d262f7871c5cc8b532971fb644f0abf">&#9670;&nbsp;</a></span>Deterministic() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const bool&amp; Deterministic </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the indicator of training mode / test mode. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00141">141</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="a1fb26736f2d90010f882f9628cd26612"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1fb26736f2d90010f882f9628cd26612">&#9670;&nbsp;</a></span>Episode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Episode </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute an episode. </p>
<dl class="section return"><dt>Returns</dt><dd>Return of the episode. </dd></dl>

</div>
</div>
<a id="abd126acd7f564c8326dc765232624ae4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd126acd7f564c8326dc765232624ae4">&#9670;&nbsp;</a></span>SelectAction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void SelectAction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Select an action, given an agent. </p>

</div>
</div>
<a id="a0e8b07b1eb04d72c36e95f795340d5c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e8b07b1eb04d72c36e95f795340d5c6">&#9670;&nbsp;</a></span>SoftUpdate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void SoftUpdate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rho</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Softly update the learning Q network parameters to the target Q network parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rho</td><td>How "softly" should the parameters be copied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad7a595de4a1a67da528603c20f80315f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7a595de4a1a67da528603c20f80315f">&#9670;&nbsp;</a></span>State() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a>&amp; State </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Modify the state of the agent. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00131">131</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="afa3e388ae5e024c8ec49fd4d1ef725ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa3e388ae5e024c8ec49fd4d1ef725ad">&#9670;&nbsp;</a></span>State() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classmlpack_1_1rl_1_1SAC.html#ada68ef405b7c331a2bee337614f00088">StateType</a>&amp; State </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the state of the agent. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00133">133</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="abaf0bb243c2e643c57654b8e65058fa0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abaf0bb243c2e643c57654b8e65058fa0">&#9670;&nbsp;</a></span>TotalSteps() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t&amp; TotalSteps </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Modify total steps from beginning. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00126">126</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="a689af4e6e564ab01f40e6ec49638bdaf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a689af4e6e564ab01f40e6ec49638bdaf">&#9670;&nbsp;</a></span>TotalSteps() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const size_t&amp; TotalSteps </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get total steps from beginning. </p>

<p class="definition">Definition at line <a class="el" href="sac_8hpp_source.html#l00128">128</a> of file <a class="el" href="sac_8hpp_source.html">sac.hpp</a>.</p>

</div>
</div>
<a id="aec0783b5a136e042adcc47bae4fe5291"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec0783b5a136e042adcc47bae4fe5291">&#9670;&nbsp;</a></span>Update()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Update </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update the Q and policy networks. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/aakash/mlpack/src/mlpack/methods/reinforcement_learning/<a class="el" href="sac_8hpp_source.html">sac.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>
